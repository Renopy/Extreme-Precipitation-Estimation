{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import netCDF4\n",
    "import pickle \n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py \n",
    "import numpy as np\n",
    "\n",
    "def Reshape( X ):\n",
    "    x =[ ]\n",
    "    for i in range(X.shape[1]):\n",
    "        x.append(X[: , i  , :])\n",
    "    return np.array(x)\n",
    "\n",
    "def rescale( data  ,Ref ) :\n",
    "    means = np.mean(Ref , axis = 0 )\n",
    "    std = np.std( Ref , axis =0)\n",
    "    return (data -means ) / std\n",
    "\n",
    "def Dict_to_hdf(Dict , of ):\n",
    "    HDF = h5py.File(of, 'w')\n",
    "    for k in Dict :    \n",
    "        test = HDF.create_dataset( k , data = np.array(Dict[k] ))\n",
    "    HDF.close()   \n",
    "\n",
    "\n",
    "def nc_to_pd(nc):\n",
    "    try:\n",
    "        Keys = list(nc.keys())\n",
    "    except:\n",
    "        Keys = list(nc.variables)\n",
    "    Panda ={ }\n",
    "    for k in Keys:\n",
    "        Panda[k]= np.array(nc[k] )    \n",
    "    return pd.DataFrame(Panda)\n",
    "\n",
    "def DF_bites_to_str(DF):\n",
    "    for k in DF :\n",
    "        if type(DF[k][0])  == np.bytes_ :\n",
    "            DF[k]  = np.array( DF[k]).astype(str)\n",
    "    return DF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Readinf rhe datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['CAL_P', 'CAL_P(-1)', 'CAL_P(-2)', 'CAL_P(-3)', 'CAL_P(-4)', 'CAL_P(-5)', 'CAL_P_ave', 'DAY', 'DEWP', 'DEWP_ATTRIBUTES', 'Date', 'ELEVATION', 'ERA5_cape', 'ERA5_cape(-1)', 'ERA5_cape(-2)', 'ERA5_cape(-3)', 'ERA5_cape(-4)', 'ERA5_cape(-5)', 'ERA5_msl', 'ERA5_msl(-1)', 'ERA5_msl(-2)', 'ERA5_msl(-3)', 'ERA5_msl(-4)', 'ERA5_msl(-5)', 'ERA5_t2m', 'ERA5_t2m(-1)', 'ERA5_t2m(-2)', 'ERA5_t2m(-3)', 'ERA5_t2m(-4)', 'ERA5_t2m(-5)', 'ERA5_tcw', 'ERA5_tcw(-1)', 'ERA5_tcw(-2)', 'ERA5_tcw(-3)', 'ERA5_tcw(-4)', 'ERA5_tcw(-5)', 'ERA5_tp', 'ERA5_tp(-1)', 'ERA5_tp(-2)', 'ERA5_tp(-3)', 'ERA5_tp(-4)', 'ERA5_tp(-5)', 'FRSHTT', 'GUST', 'HQ_P', 'HQ_P(-1)', 'HQ_P(-2)', 'HQ_P(-3)', 'HQ_P(-4)', 'HQ_P(-5)', 'LATITUDE', 'LONGITUDE', 'LSTM_RA_0', 'LSTM_RA_0(-1)', 'LSTM_RA_0(-2)', 'LSTM_RA_0(-3)', 'LSTM_RA_0(-4)', 'LSTM_RA_1', 'LSTM_RA_2', 'LSTM_RA_3', 'LSTM_RA_3(-1)', 'LSTM_RA_3(-2)', 'LSTM_RA_3(-3)', 'LSTM_RA_3(-4)', 'LSTM_RA_4', 'LSTM_RA_4(-4)', 'MAX', 'MAX_ATTRIBUTES', 'MIN', 'MIN_ATTRIBUTES', 'MONTH', 'MXSPD', 'NAME', 'PDIR', 'PDIR(-1)', 'PDIR(-2)', 'PDIR(-3)', 'PDIR(-4)', 'PDIR(-5)', 'PDIR(0)', 'PRCP', 'PRCP_ATTRIBUTES', 'SLP', 'SLP_ATTRIBUTES', 'SNDP', 'STATION', 'STP', 'STP_ATTRIBUTES', 'TEMP', 'TEMP_ATTRIBUTES', 'Unnamed: 0.1', 'VISIB', 'VISIB_ATTRIBUTES', 'WDSP', 'WDSP_ATTRIBUTES', 'YEAR', '_nc4_non_coord_string1', 'dim_0']>\n",
      "<KeysViewHDF5 ['CAL_P', 'DAY', 'LATITUDE', 'LONGITUDE', 'MONTH', 'NAME', 'PRCP', 'STATION', 'YEAR', 'state_code', 'state_name']>\n",
      "<KeysViewHDF5 ['ACO-MLP']>\n",
      "<KeysViewHDF5 ['CNN3', 'CNN3C', 'CNN5', 'CNN5C', 'CNN7', 'CNN7C']>\n",
      "<KeysViewHDF5 ['ACO-MLP', 'DAY', 'LATITUDE', 'LONGITUDE', 'MONTH', 'PRCP', 'YEAR', 'ant_cat', 'state_code']>\n",
      "<KeysViewHDF5 ['CNN7C_re', 'DAY', 'LATITUDE', 'LONGITUDE', 'MONTH', 'PRCP', 'STATE_CODE', 'STATION', 'YEAR']>\n",
      "<KeysViewHDF5 ['ERA5_cape', 'ERA5_cape_Ci_box(3, 3)', 'ERA5_cape_Ci_box(5, 5)', 'ERA5_cape_Ci_box(7, 7)', 'ERA5_cape_Cj_box(3, 3)', 'ERA5_cape_Cj_box(5, 5)', 'ERA5_cape_Cj_box(7, 7)', 'ERA5_cape_ave_box(3, 3)', 'ERA5_cape_ave_box(5, 5)', 'ERA5_cape_ave_box(7, 7)', 'ERA5_cape_std_box(3, 3)', 'ERA5_cape_std_box(5, 5)', 'ERA5_cape_std_box(7, 7)', 'ERA5_t2m', 'ERA5_t2m_Ci_box(3, 3)', 'ERA5_t2m_Ci_box(5, 5)', 'ERA5_t2m_Ci_box(7, 7)', 'ERA5_t2m_Cj_box(3, 3)', 'ERA5_t2m_Cj_box(5, 5)', 'ERA5_t2m_Cj_box(7, 7)', 'ERA5_t2m_ave_box(3, 3)', 'ERA5_t2m_ave_box(5, 5)', 'ERA5_t2m_ave_box(7, 7)', 'ERA5_t2m_std_box(3, 3)', 'ERA5_t2m_std_box(5, 5)', 'ERA5_t2m_std_box(7, 7)', 'ERA5_tcw', 'ERA5_tcw_Ci_box(3, 3)', 'ERA5_tcw_Ci_box(5, 5)', 'ERA5_tcw_Ci_box(7, 7)', 'ERA5_tcw_Cj_box(3, 3)', 'ERA5_tcw_Cj_box(5, 5)', 'ERA5_tcw_Cj_box(7, 7)', 'ERA5_tcw_ave_box(3, 3)', 'ERA5_tcw_ave_box(5, 5)', 'ERA5_tcw_ave_box(7, 7)', 'ERA5_tcw_std_box(3, 3)', 'ERA5_tcw_std_box(5, 5)', 'ERA5_tcw_std_box(7, 7)', 'ERA5_tp', 'ERA5_tp_Ci_box(3, 3)', 'ERA5_tp_Ci_box(5, 5)', 'ERA5_tp_Ci_box(7, 7)', 'ERA5_tp_Cj_box(3, 3)', 'ERA5_tp_Cj_box(5, 5)', 'ERA5_tp_Cj_box(7, 7)', 'ERA5_tp_ave_box(3, 3)', 'ERA5_tp_ave_box(5, 5)', 'ERA5_tp_ave_box(7, 7)', 'ERA5_tp_std_box(3, 3)', 'ERA5_tp_std_box(5, 5)', 'ERA5_tp_std_box(7, 7)']>\n",
      "<KeysViewHDF5 ['cape_3', 'cape_5', 'cape_7', 't2m_3', 't2m_5', 't2m_7', 'tcw_3', 'tcw_5', 'tcw_7', 'tp_3', 'tp_5', 'tp_7']>\n",
      "<KeysViewHDF5 ['CAL_P', 'CAL_P_Ci_box(3, 3)', 'CAL_P_Ci_box(5, 5)', 'CAL_P_Ci_box(7, 7)', 'CAL_P_Cj_box(3, 3)', 'CAL_P_Cj_box(5, 5)', 'CAL_P_Cj_box(7, 7)', 'CAL_P_ave_box(3, 3)', 'CAL_P_ave_box(5, 5)', 'CAL_P_ave_box(7, 7)', 'CAL_P_std_box(3, 3)', 'CAL_P_std_box(5, 5)', 'CAL_P_std_box(7, 7)']>\n",
      "<KeysViewHDF5 ['HQ_P(-1)-(13, 13)', 'HQ_P(-2)-(13, 13)', 'HQ_P(-3)-(13, 13)', 'HQ_P(-4)-(13, 13)', 'HQ_P(0)-(13, 13)']>\n",
      "<KeysViewHDF5 ['HQ_P(-1)-(7, 7)', 'HQ_P(-2)-(7, 7)', 'HQ_P(-3)-(7, 7)', 'HQ_P(-4)-(7, 7)']>\n",
      "<KeysViewHDF5 ['CAL_P(-1)-(7, 7)', 'CAL_P(-2)-(7, 7)', 'CAL_P(-3)-(7, 7)', 'CAL_P(-4)-(7, 7)']>\n",
      "<KeysViewHDF5 ['CAL_P_7']>\n",
      "<KeysViewHDF5 ['CAL_P', 'CAL_P_ave_box(3, 3)', 'CAL_P_ave_box(5, 5)', 'CAL_P_ave_box(7, 7)', 'CAL_P_std_box(3, 3)', 'CAL_P_std_box(5, 5)', 'CAL_P_std_box(7, 7)', 'CNN7', 'DAY', 'ERA5_cape', 'ERA5_cape_ave_box(3, 3)', 'ERA5_cape_ave_box(5, 5)', 'ERA5_cape_ave_box(7, 7)', 'ERA5_cape_std_box(3, 3)', 'ERA5_cape_std_box(5, 5)', 'ERA5_cape_std_box(7, 7)', 'ERA5_t2m', 'ERA5_t2m_ave_box(3, 3)', 'ERA5_t2m_ave_box(5, 5)', 'ERA5_t2m_ave_box(7, 7)', 'ERA5_t2m_std_box(3, 3)', 'ERA5_t2m_std_box(5, 5)', 'ERA5_t2m_std_box(7, 7)', 'ERA5_tcw', 'ERA5_tcw_ave_box(3, 3)', 'ERA5_tcw_ave_box(5, 5)', 'ERA5_tcw_ave_box(7, 7)', 'ERA5_tcw_std_box(3, 3)', 'ERA5_tcw_std_box(5, 5)', 'ERA5_tcw_std_box(7, 7)', 'ERA5_tp', 'ERA5_tp_ave_box(3, 3)', 'ERA5_tp_ave_box(5, 5)', 'ERA5_tp_ave_box(7, 7)', 'ERA5_tp_std_box(3, 3)', 'ERA5_tp_std_box(5, 5)', 'ERA5_tp_std_box(7, 7)', 'LATITUDE', 'LONGITUDE', 'MONTH', 'PDIR', 'PDIR_ave_box(3, 3)', 'PDIR_ave_box(5, 5)', 'PDIR_ave_box(7, 7)', 'PDIR_std_box(3, 3)', 'PDIR_std_box(5, 5)', 'PDIR_std_box(7, 7)', 'PRCP', 'STATE_CODE', 'YEAR']>\n",
      "<KeysViewHDF5 ['PDIR', 'PDIR_Ci_box(3, 3)', 'PDIR_Ci_box(5, 5)', 'PDIR_Ci_box(7, 7)', 'PDIR_Cj_box(3, 3)', 'PDIR_Cj_box(5, 5)', 'PDIR_Cj_box(7, 7)', 'PDIR_ave_box(3, 3)', 'PDIR_ave_box(5, 5)', 'PDIR_ave_box(7, 7)', 'PDIR_std_box(3, 3)', 'PDIR_std_box(5, 5)', 'PDIR_std_box(7, 7)']>\n",
      "<KeysViewHDF5 ['PDIR_3']>\n",
      "<KeysViewHDF5 ['PDIR_5']>\n",
      "<KeysViewHDF5 ['PDIR_7']>\n",
      "<KeysViewHDF5 ['DAY', 'LATITUDE', 'LONGITUDE', 'MONTH', 'NAME', 'STATION', 'YEAR', 're_CAL_P', 're_CAL_P_Ci_box(3, 3)', 're_CAL_P_Ci_box(5, 5)', 're_CAL_P_Ci_box(7, 7)', 're_CAL_P_Cj_box(3, 3)', 're_CAL_P_Cj_box(5, 5)', 're_CAL_P_Cj_box(7, 7)', 're_CAL_P_ave_box(3, 3)', 're_CAL_P_ave_box(5, 5)', 're_CAL_P_ave_box(7, 7)', 're_CAL_P_std_box(3, 3)', 're_CAL_P_std_box(5, 5)', 're_CAL_P_std_box(7, 7)', 're_ERA5_cape', 're_ERA5_cape_Ci_box(3, 3)', 're_ERA5_cape_Ci_box(5, 5)', 're_ERA5_cape_Ci_box(7, 7)', 're_ERA5_cape_Cj_box(3, 3)', 're_ERA5_cape_Cj_box(5, 5)', 're_ERA5_cape_Cj_box(7, 7)', 're_ERA5_cape_ave_box(3, 3)', 're_ERA5_cape_ave_box(5, 5)', 're_ERA5_cape_ave_box(7, 7)', 're_ERA5_cape_std_box(3, 3)', 're_ERA5_cape_std_box(5, 5)', 're_ERA5_cape_std_box(7, 7)', 're_ERA5_t2m', 're_ERA5_t2m_Ci_box(3, 3)', 're_ERA5_t2m_Ci_box(5, 5)', 're_ERA5_t2m_Ci_box(7, 7)', 're_ERA5_t2m_Cj_box(3, 3)', 're_ERA5_t2m_Cj_box(5, 5)', 're_ERA5_t2m_Cj_box(7, 7)', 're_ERA5_t2m_ave_box(3, 3)', 're_ERA5_t2m_ave_box(5, 5)', 're_ERA5_t2m_ave_box(7, 7)', 're_ERA5_t2m_std_box(3, 3)', 're_ERA5_t2m_std_box(5, 5)', 're_ERA5_t2m_std_box(7, 7)', 're_ERA5_tcw', 're_ERA5_tcw_Ci_box(3, 3)', 're_ERA5_tcw_Ci_box(5, 5)', 're_ERA5_tcw_Ci_box(7, 7)', 're_ERA5_tcw_Cj_box(3, 3)', 're_ERA5_tcw_Cj_box(5, 5)', 're_ERA5_tcw_Cj_box(7, 7)', 're_ERA5_tcw_ave_box(3, 3)', 're_ERA5_tcw_ave_box(5, 5)', 're_ERA5_tcw_ave_box(7, 7)', 're_ERA5_tcw_std_box(3, 3)', 're_ERA5_tcw_std_box(5, 5)', 're_ERA5_tcw_std_box(7, 7)', 're_ERA5_tp', 're_ERA5_tp_Ci_box(3, 3)', 're_ERA5_tp_Ci_box(5, 5)', 're_ERA5_tp_Ci_box(7, 7)', 're_ERA5_tp_Cj_box(3, 3)', 're_ERA5_tp_Cj_box(5, 5)', 're_ERA5_tp_Cj_box(7, 7)', 're_ERA5_tp_ave_box(3, 3)', 're_ERA5_tp_ave_box(5, 5)', 're_ERA5_tp_ave_box(7, 7)', 're_ERA5_tp_std_box(3, 3)', 're_ERA5_tp_std_box(5, 5)', 're_ERA5_tp_std_box(7, 7)', 're_PDIR', 're_PDIR_Ci_box(3, 3)', 're_PDIR_Ci_box(5, 5)', 're_PDIR_Ci_box(7, 7)', 're_PDIR_Cj_box(3, 3)', 're_PDIR_Cj_box(5, 5)', 're_PDIR_Cj_box(7, 7)', 're_PDIR_ave_box(3, 3)', 're_PDIR_ave_box(5, 5)', 're_PDIR_ave_box(7, 7)', 're_PDIR_std_box(3, 3)', 're_PDIR_std_box(5, 5)', 're_PDIR_std_box(7, 7)', 're_PRCP']>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Folder = \"D:/Projects/precipitation_AUS/dataset/0025/\"\n",
    "files = os.listdir(Folder)\n",
    "hdfs = []\n",
    "\n",
    "for file in files :\n",
    "    hdf = h5py.File(Folder + file , 'r+')\n",
    "    hdfs.append( hdf)\n",
    "    print(hdf.keys())\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_keys = [ 'NAME' , 'STATION' , 'LATITUDE' , 'LONGITUDE' ,  \n",
    "               'YEAR'  , 'MONTH'   ,  'DAY'  , 'PRCP'  , 'state_code'  , \n",
    "               'state_name'   ,\n",
    "                   'HQ_P(-1)-(13, 13)', 'HQ_P(-2)-(13, 13)', \n",
    "               'HQ_P(-3)-(13, 13)', 'HQ_P(-4)-(13, 13)'] \n",
    "\n",
    "DF = {}\n",
    "for k in needed_keys :\n",
    "    for hdf in hdfs :\n",
    "        if (k not in list(DF.keys())) and (k in list(hdf.keys())):\n",
    "            DF[k] = np.array(hdf[k])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decode( List, Format ):\n",
    "    a = [ ]\n",
    "    for l in List:\n",
    "        a.append(   l.decode(Format))\n",
    "    return np.array(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['NAME'] = Decode( List =list( DF['NAME']), Format = 'ascii')\n",
    "DF['state_name'] = Decode( List =list( DF['state_name']), Format = 'ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sum(L1 , L2):\n",
    "    L = []\n",
    "    for l in range(len(L1)) :\n",
    "        L.append(L1[l] + L2[l]) \n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = [  'CAL_P'  ,    'PDIR'   ,   'ERA5_tp'  , 'ERA5_cape' , 'ERA5_t2m'  ,  'ERA5_tcw'] \n",
    "\n",
    "kk1= [  'HQ_P(-1)-(7, 7)'  ,    'PDIR'   ,   'ERA5_tp'  , 'ERA5_cape' , 'ERA5_t2m'  ,  'ERA5_tcw'] #[  're_CAL_P'  ,    're_PDIR'   ,   're_ERA5_tp'  , 're_ERA5_cape' , 're_ERA5_t2m'  ,  're_ERA5_tcw'] \n",
    "\n",
    "kk =kk1 \n",
    "Ld_1 =   6*[ '(3, 3)']#['(7, 7)' , '(19, 19)'  ]     +  4*[ '(3, 3)']\n",
    "Ld_2 =  6*[ '(5, 5)'] #['(13, 13)' , '(31, 31)']     +  4*[ '(5, 5)']\n",
    "Ld_3 =  6*[ '(7, 7)'] #['(17, 17)' , '(43, 43)'  ]     +  4*[ '(7, 7)']\n",
    "\n",
    "\n",
    "ord_Keys = [  kk1    ,\n",
    "            \n",
    "        Sum([k_ +'_ave_box'  for k_ in kk1]  ,  Ld_1 ) ,\n",
    "        Sum([k_ +'_std_box'  for k_ in kk1]  ,  Ld_1 ) ,\n",
    "        Sum([k_ +'_Ci_box'  for k_ in kk1]  ,  Ld_1 ) ,\n",
    "        Sum([k_ +'_Cj_box'  for k_ in kk1]  ,  Ld_1 ) ,\n",
    "\n",
    "         Sum([k_ +'_ave_box'  for k_ in kk1]  ,  Ld_2 ) ,\n",
    "        Sum([k_ +'_std_box'  for k_ in kk1]  ,  Ld_2 ) ,\n",
    "        Sum([k_ +'_Ci_box'  for k_ in kk1]  ,  Ld_2 ) ,\n",
    "        Sum([k_ +'_Cj_box'  for k_ in kk1]  ,  Ld_2 ) ,\n",
    "        \n",
    "         Sum([k_ +'_ave_box'  for k_ in kk1]  ,  Ld_3 ) ,\n",
    "        Sum([k_ +'_std_box'  for k_ in kk1]  ,  Ld_3 ) ,\n",
    "        Sum([k_ +'_Ci_box'  for k_ in kk1]  ,  Ld_3 ) ,\n",
    "        Sum([k_ +'_Cj_box'  for k_ in kk1]  ,  Ld_3 )\n",
    "]\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "[k_ +'_ave_box(5, 5)'  for k_ in kk] ,\n",
    "[k_ +'_std_box(5, 5)'   for k_ in kk]  , \n",
    "[k_ +'_Ci_box(5, 5)'   for k_ in kk]  , \n",
    "[k_ +'_Cj_box(5, 5)'   for k_ in kk] ,\n",
    "\n",
    "[k_ +'_ave_box(7, 7)'  for k_ in kk] ,\n",
    "[k_ +'_std_box(7, 7)'   for k_ in kk]  , \n",
    "[k_ +'_Ci_box(7, 7)'   for k_ in kk]  , \n",
    "[k_ +'_Cj_box(7, 7)'   for k_ in kk] ,\n",
    "\n",
    "[k_ +'_ave_box(3, 3)'  for k_ in kk] ,\n",
    "[k_ +'_std_box(3, 3)'   for k_ in kk]  , \n",
    "[k_ +'_Ci_box(3, 3)'   for k_ in kk]  , \n",
    "[k_ +'_Cj_box(3, 3)'   for k_ in kk] ]\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "[k_ +'(-1)_ave_box(5, 5)'  for k_ in kk] ,\n",
    "[k_ +'(-1)_std_box(5, 5)'   for k_ in kk]  , \n",
    "[k_ +'(-1)_Ci_box(5, 5)'   for k_ in kk]  , \n",
    "[k_ +'(-1)_Cj_box(5, 5)'   for k_ in kk] ,\n",
    "\n",
    "[k_ +'(-1)_ave_box(7, 7)'  for k_ in kk] ,\n",
    "[k_ +'(-1)_std_box(7, 7)'   for k_ in kk]  , \n",
    "[k_ +'(-1)_Ci_box(7, 7)'   for k_ in kk]  , \n",
    "[k_ +'(-1)_Cj_box(7, 7)'   for k_ in kk] ]\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "''' \n",
    "[ 'CAL_P_ave_box(3, 3)'  ,    'PDIR_ave_box(3, 3)'   ,   'ERA5_tp_ave_box(3, 3)'] ,\n",
    "[ 'CAL_P_std_box(3, 3)'  ,    'PDIR_std_box(3, 3)'   ,   'ERA5_tp_std_box(3, 3)']  \n",
    "'''\n",
    "\n",
    "    \n",
    "''' \n",
    "[  'CAL_P(-1)'  ,    'PDIR(-1)'   ,   'ERA5_tp(-1)'     ,   'ERA5_cape(-1)'    , 'ERA5_t2m(-1)' ,  'ERA5_tcw(-1)'  ]  ,\n",
    "[  'CAL_P(-2)'  ,    'PDIR(-2)'   ,   'ERA5_tp(-2)'     ,   'ERA5_cape(-2)'    , 'ERA5_t2m(-2)' ,  'ERA5_tcw(-2)'  ]  ,\n",
    "[  'CAL_P(-3)'  ,    'PDIR(-3)'   ,   'ERA5_tp(-3)'     ,   'ERA5_cape(-3)'    , 'ERA5_t2m(-3)' ,  'ERA5_tcw(-3)'  ] , \n",
    "[  'CAL_P(-4)'  ,    'PDIR(-4)'   ,   'ERA5_tp(-4)'     ,   'ERA5_cape(-4)'    , 'ERA5_t2m(-4)' ,  'ERA5_tcw(-4)'  ] \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "ord_keys = np.array(ord_Keys) \n",
    "\n",
    "obs_key = 'PRCP' # Observations\n",
    "\n",
    "Rescale = True\n",
    "\n",
    "\n",
    "for Keys in ord_Keys:\n",
    "    for k in Keys:\n",
    "        for hdf in hdfs :\n",
    "            if k in list(hdf.keys()):\n",
    "                DF[k] = np.array(hdf[k])\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "['dim_0', 'CAL_P', 'CAL_P(-1)', 'CAL_P(-2)', 'CAL_P(-3)', 'CAL_P(-4)',\n",
    "       'CAL_P(-5)', 'DAY', 'DEWP', 'DEWP_ATTRIBUTES', 'Date', 'ELEVATION',\n",
    "       'ERA5_cape', 'ERA5_cape(-1)', 'ERA5_cape(-2)', 'ERA5_cape(-3)',\n",
    "       'ERA5_cape(-4)', 'ERA5_cape(-5)', 'ERA5_msl', 'ERA5_msl(-1)',\n",
    "       'ERA5_msl(-2)', 'ERA5_msl(-3)', 'ERA5_msl(-4)', 'ERA5_msl(-5)',\n",
    "       'ERA5_t2m', 'ERA5_t2m(-1)', 'ERA5_t2m(-2)', 'ERA5_t2m(-3)',\n",
    "       'ERA5_t2m(-4)', 'ERA5_t2m(-5)', 'ERA5_tcw', 'ERA5_tcw(-1)',\n",
    "       'ERA5_tcw(-2)', 'ERA5_tcw(-3)', 'ERA5_tcw(-4)', 'ERA5_tcw(-5)',\n",
    "       'ERA5_tp', 'ERA5_tp(-1)', 'ERA5_tp(-2)', 'ERA5_tp(-3)', 'ERA5_tp(-4)',\n",
    "       'ERA5_tp(-5)', 'FRSHTT', 'GUST', 'HQ_P', 'HQ_P(-1)', 'HQ_P(-2)',\n",
    "       'HQ_P(-3)', 'HQ_P(-4)', 'HQ_P(-5)', 'LATITUDE', 'LONGITUDE', 'MAX',\n",
    "       'MAX_ATTRIBUTES', 'MIN', 'MIN_ATTRIBUTES', 'MONTH', 'MXSPD', 'NAME',\n",
    "       'PDIR', 'PDIR(-1)', 'PDIR(-2)', 'PDIR(-3)', 'PDIR(-4)', 'PDIR(-5)',\n",
    "       'PDIR(0)', 'PRCP', 'PRCP_ATTRIBUTES', 'SLP', 'SLP_ATTRIBUTES', 'SNDP',\n",
    "       'STATION', 'STP', 'STP_ATTRIBUTES', 'TEMP', 'TEMP_ATTRIBUTES',\n",
    "       'Unnamed: 0.1', 'VISIB', 'VISIB_ATTRIBUTES', 'WDSP', 'WDSP_ATTRIBUTES',\n",
    "       'YEAR']\n",
    "       \n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF[DF['state_code' ] == 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hdf in hdfs: hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Split(DF):\n",
    "    df_train = DF[DF['YEAR']  <= 2020  ]\n",
    "    df_test = DF[DF['YEAR']  > 2020]\n",
    "\n",
    "    df = {}\n",
    "\n",
    "    df['train']  , df['test']  =  df_train , df_test\n",
    "\n",
    "\n",
    "    X = {}\n",
    "\n",
    "    X_train =[]\n",
    "    X_test =[]\n",
    "\n",
    "    X_DF = []\n",
    "\n",
    "    for K in ord_Keys : \n",
    "\n",
    "        X['train'] = df['train'][ K  ].values\n",
    "        X['test'] = df['test'][ K  ].values\n",
    "\n",
    "        #X_train.append(rescale(  X['train'] , X['train']  )) \n",
    "        #X_test.append( rescale(  X['test'] , X['train']  ) )\n",
    "        X_train.append(X['train']) \n",
    "        X_test.append(  X['test'])\n",
    "        X_DF.append(rescale(   DF[ K  ].values , X['train']  ))\n",
    "\n",
    "    obs_train  = np.array(df['train'][obs_key])\n",
    "    obs_test = np.array(df['test'][obs_key])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    X_DF  = np.array(X_DF)\n",
    "\n",
    "    return  X_train , X_test , X_DF  , obs_train , obs_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183874, 13, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train , X_test , X_DF  , obs_train , obs_test = Split(DF)\n",
    "obs_test = np.transpose([obs_test]) \n",
    "obs_train = np.transpose([obs_train]) \n",
    "x_train =  Reshape(X_train)\n",
    "x_test  = Reshape(X_test)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183874, 13, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Conv2D , MaxPooling1D\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 3, 3, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S4055367\\AppData\\Local\\anaconda3\\envs\\ML\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,184</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m1,184\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m3,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m3,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,665</span> (53.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,665\u001b[0m (53.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,665</span> (53.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,665\u001b[0m (53.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 68.5778\n",
      "Epoch 2/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 34.4026\n",
      "Epoch 3/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 31.0408\n",
      "Epoch 4/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 31.7760\n",
      "Epoch 5/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 28.9844\n",
      "Epoch 6/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.8847\n",
      "Epoch 7/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 30.3964\n",
      "Epoch 8/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 28.9217\n",
      "Epoch 9/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 28.6438\n",
      "Epoch 10/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 28.8599\n",
      "Epoch 11/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.7768\n",
      "Epoch 12/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 28.2929\n",
      "Epoch 13/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 28.7478\n",
      "Epoch 14/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 29.0064\n",
      "Epoch 15/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 29.9578\n",
      "Epoch 16/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.9775\n",
      "Epoch 17/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.7219\n",
      "Epoch 18/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 29.2948\n",
      "Epoch 19/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 29.9164\n",
      "Epoch 20/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.9204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b9dbf5c1d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Params = {  \n",
    "    'layers': [32]*6,\n",
    "    'activation_function'  : ['relu']*6 ,\n",
    "    'kernels' : [ 6, 3 , 3 ]  + 3 * [ 2 ],\n",
    "    'n_epoch': 20,\n",
    "    'size_batch' : 1000,\n",
    "    'Optimizer' : 'adam'\n",
    " }\n",
    "\n",
    "print( Params['kernels'])\n",
    "x_train =  Reshape(X_train)\n",
    "x_test  = Reshape(X_test)\n",
    "\n",
    "i = 0\n",
    "\n",
    "model = Sequential() \n",
    "\n",
    "model.add(layers.Conv1D(Params['layers'][0], kernel_size= Params['kernels'][0] , activation=Params['activation_function'][0] , input_shape=  (  x_train.shape[1], x_train.shape[2] )))\n",
    "\n",
    "for i in range(1,len(Params['layers'])):\n",
    "    model.add(layers.Conv1D(Params['layers'][i], kernel_size= Params['kernels'][i] , activation=Params['activation_function'][i] ))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mse\", optimizer= Params['Optimizer'])\n",
    "model.summary()         \n",
    "model.fit( x_train, obs_train, batch_size=Params['size_batch'],epochs=Params['n_epoch'], verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2864/2864\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = DF[DF['YEAR']>2020]['ERA5_tp'].values\n",
    "y = model.predict(x_test).T[0]\n",
    "\n",
    "import evaluation_tools as ev\n",
    "\n",
    "ev.evaluation_criteria( obs_test.T[0] , y   , th=0.1,\n",
    "    threshold_heavy=25,\n",
    "    threshold_ex=60,\n",
    "    interval=[ i  for i in [ 0 , 5 , 10 , 25 , 60  , 100]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "      <th>...</th>\n",
       "      <th>ERA5_cape_Ci_box(7, 7)</th>\n",
       "      <th>ERA5_t2m_Ci_box(7, 7)</th>\n",
       "      <th>ERA5_tcw_Ci_box(7, 7)</th>\n",
       "      <th>CAL_P_Cj_box(7, 7)</th>\n",
       "      <th>PDIR_Cj_box(7, 7)</th>\n",
       "      <th>ERA5_tp_Cj_box(7, 7)</th>\n",
       "      <th>ERA5_cape_Cj_box(7, 7)</th>\n",
       "      <th>ERA5_t2m_Cj_box(7, 7)</th>\n",
       "      <th>ERA5_tcw_Cj_box(7, 7)</th>\n",
       "      <th>CNN7C_WA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4473</th>\n",
       "      <td>ADELE ISLAND</td>\n",
       "      <td>94210099999</td>\n",
       "      <td>-15.516667</td>\n",
       "      <td>123.150000</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128144</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.012143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.845747</td>\n",
       "      <td>0.222754</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-0.010855</td>\n",
       "      <td>4.160448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>ADELE ISLAND</td>\n",
       "      <td>94210099999</td>\n",
       "      <td>-15.516667</td>\n",
       "      <td>123.150000</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200073</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.065578</td>\n",
       "      <td>1.947804</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.396486</td>\n",
       "      <td>0.228492</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.054885</td>\n",
       "      <td>1.320142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>ADELE ISLAND</td>\n",
       "      <td>94210099999</td>\n",
       "      <td>-15.516667</td>\n",
       "      <td>123.150000</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123733</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.045070</td>\n",
       "      <td>-1.661212</td>\n",
       "      <td>-0.178571</td>\n",
       "      <td>1.318761</td>\n",
       "      <td>0.147785</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>2.808842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>ADELE ISLAND</td>\n",
       "      <td>94210099999</td>\n",
       "      <td>-15.516667</td>\n",
       "      <td>123.150000</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126926</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>-0.008788</td>\n",
       "      <td>0.971650</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>-1.421813</td>\n",
       "      <td>0.164949</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.038771</td>\n",
       "      <td>3.035832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>ADELE ISLAND</td>\n",
       "      <td>94210099999</td>\n",
       "      <td>-15.516667</td>\n",
       "      <td>123.150000</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172677</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.015230</td>\n",
       "      <td>0.015276</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>1.592692</td>\n",
       "      <td>-0.045095</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>1.970360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512030</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003485</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>-0.097175</td>\n",
       "      <td>1.904465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512031</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007224</td>\n",
       "      <td>0.040701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009360</td>\n",
       "      <td>-0.063425</td>\n",
       "      <td>1.886548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512032</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009787</td>\n",
       "      <td>-0.174400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>0.067201</td>\n",
       "      <td>1.619642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512033</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>-0.148966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>-0.004677</td>\n",
       "      <td>1.750081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512034</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>0.061933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.221450</td>\n",
       "      <td>1.946474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275520 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          NAME      STATION   LATITUDE   LONGITUDE  YEAR  \\\n",
       "4473              ADELE ISLAND  94210099999 -15.516667  123.150000  2014   \n",
       "4474              ADELE ISLAND  94210099999 -15.516667  123.150000  2014   \n",
       "4475              ADELE ISLAND  94210099999 -15.516667  123.150000  2014   \n",
       "4476              ADELE ISLAND  94210099999 -15.516667  123.150000  2014   \n",
       "4477              ADELE ISLAND  94210099999 -15.516667  123.150000  2014   \n",
       "...                        ...          ...        ...         ...   ...   \n",
       "1512030  DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "1512031  DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "1512032  DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "1512033  DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "1512034  DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "\n",
       "         MONTH  DAY  PRCP  state_code            state_name  ...  \\\n",
       "4473         1    1   0.0           5  b'Western Australia'  ...   \n",
       "4474         1    2   0.0           5  b'Western Australia'  ...   \n",
       "4475         1    3   0.0           5  b'Western Australia'  ...   \n",
       "4476         1    4   0.0           5  b'Western Australia'  ...   \n",
       "4477         1    5   0.0           5  b'Western Australia'  ...   \n",
       "...        ...  ...   ...         ...                   ...  ...   \n",
       "1512030      1   27   0.0           5  b'Western Australia'  ...   \n",
       "1512031      1   28   0.0           5  b'Western Australia'  ...   \n",
       "1512032      1   29   0.0           5  b'Western Australia'  ...   \n",
       "1512033      1   30   0.0           5  b'Western Australia'  ...   \n",
       "1512034      1   31   0.0           5  b'Western Australia'  ...   \n",
       "\n",
       "         ERA5_cape_Ci_box(7, 7)  ERA5_t2m_Ci_box(7, 7)  ERA5_tcw_Ci_box(7, 7)  \\\n",
       "4473                   0.128144               0.000711               0.012143   \n",
       "4474                   0.200073               0.001209               0.065578   \n",
       "4475                   0.123733               0.001127               0.045070   \n",
       "4476                   0.126926               0.001199              -0.008788   \n",
       "4477                   0.172677               0.000264              -0.015230   \n",
       "...                         ...                    ...                    ...   \n",
       "1512030                0.000000              -0.003485               0.066814   \n",
       "1512031                0.000000              -0.007224               0.040701   \n",
       "1512032                0.000000              -0.009787              -0.174400   \n",
       "1512033                0.000000              -0.009386              -0.148966   \n",
       "1512034                0.000000              -0.004851               0.061933   \n",
       "\n",
       "         CAL_P_Cj_box(7, 7)  PDIR_Cj_box(7, 7)  ERA5_tp_Cj_box(7, 7)  \\\n",
       "4473               1.000000           0.000000             -1.845747   \n",
       "4474               1.947804           0.666667              1.396486   \n",
       "4475              -1.661212          -0.178571              1.318761   \n",
       "4476               0.971650           0.023669             -1.421813   \n",
       "4477               0.015276           0.478723              1.592692   \n",
       "...                     ...                ...                   ...   \n",
       "1512030            0.000000           0.000000              0.000000   \n",
       "1512031            0.000000           0.000000              0.000000   \n",
       "1512032            0.000000           0.000000              0.000000   \n",
       "1512033            0.000000           0.000000              0.000000   \n",
       "1512034            0.000000           0.000000              0.000000   \n",
       "\n",
       "         ERA5_cape_Cj_box(7, 7)  ERA5_t2m_Cj_box(7, 7)  ERA5_tcw_Cj_box(7, 7)  \\\n",
       "4473                   0.222754               0.001000              -0.010855   \n",
       "4474                   0.228492               0.001586               0.054885   \n",
       "4475                   0.147785               0.000905               0.020605   \n",
       "4476                   0.164949               0.000420               0.038771   \n",
       "4477                  -0.045095               0.000190               0.020965   \n",
       "...                         ...                    ...                    ...   \n",
       "1512030                0.000000               0.002843              -0.097175   \n",
       "1512031                0.000000               0.009360              -0.063425   \n",
       "1512032                0.000000               0.005641               0.067201   \n",
       "1512033                0.000000               0.002731              -0.004677   \n",
       "1512034                0.000000               0.000670              -0.221450   \n",
       "\n",
       "         CNN7C_WA  \n",
       "4473     4.160448  \n",
       "4474     1.320142  \n",
       "4475     2.808842  \n",
       "4476     3.035832  \n",
       "4477     1.970360  \n",
       "...           ...  \n",
       "1512030  1.904465  \n",
       "1512031  1.886548  \n",
       "1512032  1.619642  \n",
       "1512033  1.750081  \n",
       "1512034  1.946474  \n",
       "\n",
       "[275520 rows x 90 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91646, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_test.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8610/8610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# save the model in parent Data Frame \n",
    "\n",
    "model_name = 'CNN7C_WA'\n",
    "\n",
    "x_DF = Reshape(X_DF)\n",
    "DF_predict =  model.predict( x_DF )  \n",
    "DF[model_name] =  np.transpose(DF_predict)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the CNN model in hdf format\n",
    "\n",
    "model.save(  '../models-2/' + model_name + '.keras' )\n",
    "Params['name']  = model_name \n",
    "Params['ord_keys']  = ord_Keys\n",
    "Dict_to_hdf( Dict= Params  , of = '../models-2/' + model_name + '.hdf5' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add joint ant-colony Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mealpy\n",
    "import numpy\n",
    "from mealpy import ACOR\n",
    "import numpy as np\n",
    "from mealpy import FloatVar, ACOR\n",
    "Sols = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP :\n",
    "    def __init__(self, nn_shape , inp_feat ):\n",
    "        self.nn_shape = nn_shape\n",
    "\n",
    "        self.inp_feat = inp_feat\n",
    "\n",
    "        self.W_Shapes = []\n",
    "        self.B_Shapes = []\n",
    "\n",
    "        for i in range(len(self.nn_shape)):\n",
    "            if i == 0 :\n",
    "                self.W_Shapes .append(  (self.inp_feat,  self.nn_shape[i])    )    \n",
    "            else:\n",
    "                self.W_Shapes .append(  (self.nn_shape[i-1],self.nn_shape[i])    )\n",
    "            self.B_Shapes .append(   self.nn_shape[i] )\n",
    "        self.W_Shapes.append((self.nn_shape[-1] , 1))\n",
    "        self.B_Shapes .append(  1 )\n",
    "        self.w_params =[]\n",
    "\n",
    "        for I in self.W_Shapes:\n",
    "            self.w_params.append(  I[0]*I[1]    )\n",
    "\n",
    "        self.Sum_params = sum(self.w_params ) +sum(self.B_Shapes)\n",
    "    \n",
    "\n",
    "    def update(self, solution):\n",
    "        ii = 0\n",
    "        self.W = []\n",
    "        for i in range(len(self.W_Shapes)) : \n",
    "            a = np.array(solution[ ii  : ii  + self.w_params[i] ])\n",
    "            self.W.append( np.reshape(a, self.W_Shapes[i]))\n",
    "            ii = ii  + self.w_params[i] \n",
    "        self.B= []\n",
    "        for i in range(len(self.B_Shapes)) :\n",
    "            a = np.array(solution[ ii  : ii  + self.B_Shapes[i] ])\n",
    "            self.B.append( a )\n",
    "            ii = ii  +  self.B_Shapes[i]\n",
    "        self.number_of_layers = len(self.W)\n",
    "        \n",
    "    def feed_forward(self , X ):\n",
    "        for i in range(self.number_of_layers):\n",
    "            h = numpy.dot(X,numpy.array(self.W[i])) + self.B[i]\n",
    "            if i!= self.number_of_layers-1:\n",
    "                # Xa = numpy.tanh(h)\n",
    "                # X = numpy.maximum(h,0) \n",
    "                X= np.tanh(h)\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_ant = train_predict\n",
    "obs_train_ant = columnar(obs_train)\n",
    "obs_test_ant = columnar(obs_test)\n",
    "ep = 1E-10\n",
    "\n",
    "def sgn(x , th):\n",
    "    return ((x - th + ep ) / np.absolute(x - th  +ep)  + 1)/2 \n",
    "\n",
    "def CSI(  O , M ,th ):\n",
    "    fo = sgn(O , th)\n",
    "    fm = sgn(M ,th)\n",
    "    return np.sum(fo * fm )  /  (np.sum(fo +fm) - np.sum(fo*fm))\n",
    "\n",
    "mlp_model = MLP(nn_shape= [20 ,10, 1 ] , inp_feat=  x_train_ant.shape[1])\n",
    "\n",
    "def fitness_function( solution  ):\n",
    "    # solution =  solution/sqrt(number_of_parameters)\n",
    "    mlp_model.update( solution)\n",
    "    y  =  mlp_model.feed_forward(x_train_ant)\n",
    "    return np.mean((y-obs_train_ant)**2)**0.5 /8  -  CSI(obs_train_ant , y  , 1 )   -  CSI(obs_train_ant , y  , 25 )   -  CSI(obs_train_ant , y  , 60 )\n",
    "import numpy\n",
    "n_var = mlp_model.Sum_params\n",
    "\n",
    "problem_dict = {\n",
    "    \"bounds\": FloatVar(  lb=(-1.,) * n_var, ub=(1.,) * n_var, name=\"delta\"),\n",
    "    \"obj_func\": fitness_function,\n",
    "    \"minmax\": \"min\",}\n",
    "\n",
    "model_ant = ACOR.OriginalACOR(epoch=20, pop_size=20, sample_count = 25, intent_factor = 0.5, zeta = 1.0)\n",
    "\n",
    "g_best = model_ant.solve(problem_dict)\n",
    "x_test_ant =  test_pr\n",
    "mlp_model.update( g_best.solution)\n",
    "y_ant = mlp_model.feed_forward(x_test_ant)[:, 0]\n",
    "ev.evaluation_criteria(obs_test  , test_pr.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:   0%|\u001b[34m                                                \u001b[0m| 2/1999 [00:01<21:43,  1.53it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7510951186180116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:   0%|\u001b[34m                                                \u001b[0m| 5/1999 [00:03<21:33,  1.54it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.009309373257960274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:   0%|\u001b[34m▏                                               \u001b[0m| 9/1999 [00:05<20:56,  1.58it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.036620084908864536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:   1%|\u001b[34m▎                                              \u001b[0m| 13/1999 [00:08<20:46,  1.59it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05318183507659785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:   2%|\u001b[34m▉                                              \u001b[0m| 39/1999 [00:24<20:01,  1.63it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05724414260595595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:  11%|\u001b[34m████▉                                         \u001b[0m| 216/1999 [02:18<18:37,  1.59it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0642947157315395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:  20%|\u001b[34m█████████▏                                    \u001b[0m| 397/1999 [04:18<16:35,  1.61it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06516688438247054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:  36%|\u001b[34m████████████████▍                             \u001b[0m| 715/1999 [07:54<15:24,  1.39it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06660472251938493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:  37%|\u001b[34m█████████████████▏                            \u001b[0m| 746/1999 [08:15<14:57,  1.40it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06669442722985175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:  40%|\u001b[34m██████████████████▎                           \u001b[0m| 796/1999 [08:50<17:12,  1.17it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06733267129589426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:  42%|\u001b[34m███████████████████                           \u001b[0m| 831/1999 [09:16<16:40,  1.17it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06839508065673955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:  90%|\u001b[34m████████████████████████████████████████▌    \u001b[0m| 1804/1999 [21:51<02:20,  1.39it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06877234826195366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization:  92%|\u001b[34m█████████████████████████████████████████▌   \u001b[0m| 1847/1999 [22:25<02:47,  1.10s/it]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06916075692759616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimization: 100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 1999/1999 [24:34<00:00,  1.36it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import PFA\n",
    "pfa = PFA.model( fitness_function =  fitness_function  , num_of_parameters= n_var , initialize_iteration= 500  \n",
    "                , PFA_iteration=2000 ,  alpha =1  , beta=2 , converging_threshold = 0.001  , lb =-1, ub=1 ) \n",
    "pfa.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15569/15569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "x_test_ant =  np.maximum(0 ,model.predict(x_test))\n",
    "mlp_model.update( pfa.best_sol )\n",
    "y_ant = mlp_model.feed_forward(x_test_ant)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save BP-ACO CNN model to the Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47252/47252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "x_DF = Reshape(X_DF)\n",
    "DF_x_ant =  np.maximum(0 ,model.predict(x_DF))\n",
    "mlp_model.update(g_best.solution)\n",
    "\n",
    "DF['BP-ACO'] = mlp_model.feed_forward(DF_x_ant)[:, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE ant colony model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../models/BP-ACO/ACO.pickle', 'wb') as file:\n",
    "    pickle.dump(model_ant, file) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0.3430829862328954,\n",
       " 'NSE': -0.012415454546291782,\n",
       " 'RMSE': 8.263964413432108,\n",
       " 'MAE': 2.1372872484419103,\n",
       " 'MBE': -1.7212630685050223,\n",
       " 'PBIAS': -80.56183882011342,\n",
       " 'KGE': -0.40855966605405536,\n",
       " 'spearman': 0.6295715465510126,\n",
       " 'std': 0.40642440671024893,\n",
       " 'obs_std': 8.213136775672716,\n",
       " 'r_heavy': 0.8367255449586488,\n",
       " 'NSE_heavy': -0.037409305104493695,\n",
       " 'RMSE_heavy': 53.56382418450034,\n",
       " 'MAE_heavy': 45.49660300997694,\n",
       " 'MBE_heavy': -45.49660300997694,\n",
       " 'PBIAS_heavy': -97.8850110416491,\n",
       " 'KGE_heavy': -0.2566458998169181,\n",
       " 'spearman_heavy': 0.3981430400322417,\n",
       " 'std_obs_heavy': 28.272168034508795,\n",
       " 'std_model_heavy': 0.08576661310349343,\n",
       " 'r_ext': 0.9101845071937796,\n",
       " 'NSE_ext': -0.021479567981049774,\n",
       " 'RMSE_ext': 99.46692307634689,\n",
       " 'MAE_ext': 91.20668343445136,\n",
       " 'MBE_ext': -91.20668343445136,\n",
       " 'PBIAS_ext': -98.92884467508961,\n",
       " 'KGE_ext': -0.24922663780662546,\n",
       " 'spearman_ext': 0.28659997592387715,\n",
       " 'std_obs_ext': 39.68935435534869,\n",
       " 'std_model_ext': 0.07122619623830832,\n",
       " 'POD': 0.952671120110516,\n",
       " 'FAR': 0.5680009611038965,\n",
       " 'BIAS': 2.205262128695696,\n",
       " 'CSI': 0.42292236650135395,\n",
       " 'POD_heavy': 0.0,\n",
       " 'FAR_heavy': 'Undefined',\n",
       " 'BIAS_heavy': 0.0,\n",
       " 'CSI_heavy': 0.0,\n",
       " 'POD_ex': 0.0,\n",
       " 'FAR_ex': 'Undefined',\n",
       " 'BIAS_ex': 0.0,\n",
       " 'CSI_ex': 0.0,\n",
       " 'KS': -1.0,\n",
       " 'P_value(t-test)': None}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluation_tools\n",
    "\n",
    "evaluation_tools.evaluation_criteria(obs_test_ant , y_ant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit CNN based on the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S4055367\\AppData\\Local\\anaconda3\\envs\\ML\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m2,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m12,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m12,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,905</span> (202.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,905\u001b[0m (202.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,905</span> (202.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,905\u001b[0m (202.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 40.6251\n",
      "Epoch 2/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 31.8162\n",
      "Epoch 3/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 31.0724\n",
      "Epoch 4/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 33.0092\n",
      "Epoch 5/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 27.0899\n",
      "Epoch 6/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 31.4914\n",
      "Epoch 7/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 28.1554\n",
      "Epoch 8/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 30.3491\n",
      "Epoch 9/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 33.0283\n",
      "Epoch 10/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 30.7380\n",
      "Epoch 11/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 28.4940\n",
      "Epoch 12/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 27.6957\n",
      "Epoch 13/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 27.6112\n",
      "Epoch 14/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 29.9683\n",
      "Epoch 15/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 26.6710\n",
      "Epoch 16/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 28.6639\n",
      "Epoch 17/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 29.0876\n",
      "Epoch 18/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 29.2965\n",
      "Epoch 19/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 30.5610\n",
      "Epoch 20/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 27.5240\n",
      "\u001b[1m8610/8610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S4055367\\AppData\\Local\\Temp\\ipykernel_17228\\4198816567.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  DF_u['CNN7C-cat']  = model.predict(x_DF)\n",
      "c:\\Users\\S4055367\\AppData\\Local\\anaconda3\\envs\\ML\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m2,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m12,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m12,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,905</span> (202.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,905\u001b[0m (202.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,905</span> (202.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,905\u001b[0m (202.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 30ms/step - loss: 37.7469\n",
      "Epoch 2/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 33.0074\n",
      "Epoch 3/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - loss: 31.5694\n",
      "Epoch 4/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 31.9593\n",
      "Epoch 5/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 31.0661\n",
      "Epoch 6/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 31.8565\n",
      "Epoch 7/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 31.4425\n",
      "Epoch 8/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - loss: 31.2728\n",
      "Epoch 9/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - loss: 29.6203\n",
      "Epoch 10/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 43ms/step - loss: 30.5646\n",
      "Epoch 11/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - loss: 29.9679\n",
      "Epoch 12/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 30.5990\n",
      "Epoch 13/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 30.6745\n",
      "Epoch 14/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 30.0957\n",
      "Epoch 15/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 29.1249\n",
      "Epoch 16/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - loss: 29.8099\n",
      "Epoch 17/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - loss: 29.3405\n",
      "Epoch 18/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 45ms/step - loss: 29.4005\n",
      "Epoch 19/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 23ms/step - loss: 29.6281\n",
      "Epoch 20/20\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 30.0771\n",
      "\u001b[1m47252/47252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "category_key = 'state_code'\n",
    "\n",
    "uniqs = DF[category_key].unique()\n",
    "uniqs = [ 5  , 0 ]\n",
    "\n",
    "uniqs\n",
    "Params = {  \n",
    "    'layers': [64]*6,\n",
    "    'activation_function'  : ['relu']*6 ,\n",
    "    'kernels' : [   6 , 3  ,3  ]   + 4* [ 2],\n",
    "    'n_epoch': 20,\n",
    "    'size_batch' : 1000,\n",
    "    'Optimizer' : 'adam'\n",
    " }\n",
    "\n",
    "DFU =[ ]\n",
    "\n",
    "for u in uniqs :\n",
    "    if u == 5:\n",
    "        DF_u = DF[DF[category_key]==u] \n",
    "    else: \n",
    "        DF_u = DF[DF[category_key]!=u] \n",
    "\n",
    "    X_train , X_test , X_DF  , obs_train , obs_test = Split(DF_u) \n",
    "    x_train =  Reshape(X_train)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    model = Sequential() \n",
    "\n",
    "    model.add(layers.Conv1D(Params['layers'][0], kernel_size= Params['kernels'][0] , activation=Params['activation_function'][0] , input_shape=  (  x_train.shape[1], x_train.shape[2] )))\n",
    "\n",
    "    for i in range(1,len(Params['layers'])):\n",
    "        model.add(layers.Conv1D(Params['layers'][i], kernel_size= Params['kernels'][i] , activation=Params['activation_function'][i] ))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer= Params['Optimizer'])\n",
    "    model.summary()         \n",
    "    model.fit( x_train, obs_train, batch_size=Params['size_batch'],epochs=Params['n_epoch'], verbose=1)\n",
    "    x_DF = Reshape(X_DF)\n",
    "    DF_u['CNN7C-cat']  = model.predict(x_DF)\n",
    "    DFU.append(DF_u)\n",
    "\n",
    "DFU = pd.concat(DFU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DFU.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "      <th>...</th>\n",
       "      <th>ERA5_cape_Ci_box(7, 7)</th>\n",
       "      <th>ERA5_t2m_Ci_box(7, 7)</th>\n",
       "      <th>ERA5_tcw_Ci_box(7, 7)</th>\n",
       "      <th>CAL_P_Cj_box(7, 7)</th>\n",
       "      <th>PDIR_Cj_box(7, 7)</th>\n",
       "      <th>ERA5_tp_Cj_box(7, 7)</th>\n",
       "      <th>ERA5_cape_Cj_box(7, 7)</th>\n",
       "      <th>ERA5_t2m_Cj_box(7, 7)</th>\n",
       "      <th>ERA5_tcw_Cj_box(7, 7)</th>\n",
       "      <th>CNN7C-cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADELAIDE INTERNATIONAL</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4</td>\n",
       "      <td>b'South Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>1.418659</td>\n",
       "      <td>-0.013557</td>\n",
       "      <td>0.084304</td>\n",
       "      <td>-0.109866</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>-0.207060</td>\n",
       "      <td>-0.226859</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>-0.060191</td>\n",
       "      <td>3.700790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADELAIDE INTERNATIONAL</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4</td>\n",
       "      <td>b'South Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>1.408637</td>\n",
       "      <td>-0.007746</td>\n",
       "      <td>-0.035550</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>-0.117315</td>\n",
       "      <td>-0.591619</td>\n",
       "      <td>-0.003511</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>3.354129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADELAIDE INTERNATIONAL</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4</td>\n",
       "      <td>b'South Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344244</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>1.095601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.344888</td>\n",
       "      <td>-0.221085</td>\n",
       "      <td>-0.001845</td>\n",
       "      <td>-0.044906</td>\n",
       "      <td>6.619004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADELAIDE INTERNATIONAL</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>b'South Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666816</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>0.112376</td>\n",
       "      <td>1.269101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.614694</td>\n",
       "      <td>-0.246672</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>-0.057649</td>\n",
       "      <td>3.295098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADELAIDE INTERNATIONAL</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.40</td>\n",
       "      <td>4</td>\n",
       "      <td>b'South Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770680</td>\n",
       "      <td>-0.001525</td>\n",
       "      <td>0.044345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.341252</td>\n",
       "      <td>0.029001</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>-0.027719</td>\n",
       "      <td>3.591348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512032</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009787</td>\n",
       "      <td>-0.174400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>0.067201</td>\n",
       "      <td>0.499223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512033</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>-0.148966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>-0.004677</td>\n",
       "      <td>0.515317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512033</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>-0.148966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>-0.004677</td>\n",
       "      <td>3.228220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512034</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>0.061933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.221450</td>\n",
       "      <td>0.637822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512034</th>\n",
       "      <td>DALWALLINU COMPARISON</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>b'Western Australia'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>0.061933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.221450</td>\n",
       "      <td>1.055027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1787555 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NAME      STATION   LATITUDE   LONGITUDE  YEAR  \\\n",
       "0        ADELAIDE INTERNATIONAL  94672099999 -34.945000  138.530556  2014   \n",
       "1        ADELAIDE INTERNATIONAL  94672099999 -34.945000  138.530556  2014   \n",
       "2        ADELAIDE INTERNATIONAL  94672099999 -34.945000  138.530556  2014   \n",
       "3        ADELAIDE INTERNATIONAL  94672099999 -34.945000  138.530556  2014   \n",
       "4        ADELAIDE INTERNATIONAL  94672099999 -34.945000  138.530556  2014   \n",
       "...                         ...          ...        ...         ...   ...   \n",
       "1512032   DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "1512033   DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "1512033   DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "1512034   DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "1512034   DALWALLINU COMPARISON  94619099999 -30.283333  116.666667  2024   \n",
       "\n",
       "         MONTH  DAY  PRCP  state_code            state_name  ...  \\\n",
       "0            1    1  4.56           4    b'South Australia'  ...   \n",
       "1            1    2  1.44           4    b'South Australia'  ...   \n",
       "2            1    3  0.24           4    b'South Australia'  ...   \n",
       "3            1    4  0.00           4    b'South Australia'  ...   \n",
       "4            1    5  2.40           4    b'South Australia'  ...   \n",
       "...        ...  ...   ...         ...                   ...  ...   \n",
       "1512032      1   29  0.00           5  b'Western Australia'  ...   \n",
       "1512033      1   30  0.00           5  b'Western Australia'  ...   \n",
       "1512033      1   30  0.00           5  b'Western Australia'  ...   \n",
       "1512034      1   31  0.00           5  b'Western Australia'  ...   \n",
       "1512034      1   31  0.00           5  b'Western Australia'  ...   \n",
       "\n",
       "         ERA5_cape_Ci_box(7, 7)  ERA5_t2m_Ci_box(7, 7)  ERA5_tcw_Ci_box(7, 7)  \\\n",
       "0                      1.418659              -0.013557               0.084304   \n",
       "1                      1.408637              -0.007746              -0.035550   \n",
       "2                      0.344244              -0.001788               0.017928   \n",
       "3                      1.666816              -0.000534               0.112376   \n",
       "4                      0.770680              -0.001525               0.044345   \n",
       "...                         ...                    ...                    ...   \n",
       "1512032                0.000000              -0.009787              -0.174400   \n",
       "1512033                0.000000              -0.009386              -0.148966   \n",
       "1512033                0.000000              -0.009386              -0.148966   \n",
       "1512034                0.000000              -0.004851               0.061933   \n",
       "1512034                0.000000              -0.004851               0.061933   \n",
       "\n",
       "         CAL_P_Cj_box(7, 7)  PDIR_Cj_box(7, 7)  ERA5_tp_Cj_box(7, 7)  \\\n",
       "0                 -0.109866           0.351351             -0.207060   \n",
       "1                  0.003568           0.358974             -0.117315   \n",
       "2                  1.095601           0.000000             -0.344888   \n",
       "3                  1.269101           0.000000             -0.614694   \n",
       "4                  1.000000           0.000000             -0.341252   \n",
       "...                     ...                ...                   ...   \n",
       "1512032            0.000000           0.000000              0.000000   \n",
       "1512033            0.000000           0.000000              0.000000   \n",
       "1512033            0.000000           0.000000              0.000000   \n",
       "1512034            0.000000           0.000000              0.000000   \n",
       "1512034            0.000000           0.000000              0.000000   \n",
       "\n",
       "         ERA5_cape_Cj_box(7, 7)  ERA5_t2m_Cj_box(7, 7)  ERA5_tcw_Cj_box(7, 7)  \\\n",
       "0                     -0.226859               0.003936              -0.060191   \n",
       "1                     -0.591619              -0.003511               0.003719   \n",
       "2                     -0.221085              -0.001845              -0.044906   \n",
       "3                     -0.246672              -0.002421              -0.057649   \n",
       "4                      0.029001              -0.001522              -0.027719   \n",
       "...                         ...                    ...                    ...   \n",
       "1512032                0.000000               0.005641               0.067201   \n",
       "1512033                0.000000               0.002731              -0.004677   \n",
       "1512033                0.000000               0.002731              -0.004677   \n",
       "1512034                0.000000               0.000670              -0.221450   \n",
       "1512034                0.000000               0.000670              -0.221450   \n",
       "\n",
       "         CNN7C-cat  \n",
       "0         3.700790  \n",
       "1         3.354129  \n",
       "2         6.619004  \n",
       "3         3.295098  \n",
       "4         3.591348  \n",
       "...            ...  \n",
       "1512032   0.499223  \n",
       "1512033   0.515317  \n",
       "1512033   3.228220  \n",
       "1512034   0.637822  \n",
       "1512034   1.055027  \n",
       "\n",
       "[1787555 rows x 90 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFU.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation_tools as ev\n",
    "\n",
    "ev.evaluation_criteria( np.array(DF[obs_key])  , np.array(DF['CNN7C-cat']   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15569/15569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step\n",
      "\u001b[1m31683/31683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6798494914843447"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "\n",
    "y_test = model.predict(x_test)\n",
    "predicted_test = numpy.transpose(y_test)[0]\n",
    "\n",
    "y_train = model.predict(x_train)\n",
    "predicted_train = numpy.transpose(y_train)[0]\n",
    "np.corrcoef( predicted_test  , obs_test )[0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the model in parent Data Frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model( 'D:/Projects/precipitation_AUS/models-2/CNN7C_re.keras' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47252/47252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# save the model in parent Data Frame \n",
    "\n",
    "model_name = 'CNN7C_re'\n",
    "x_DF = Reshape(X_DF)\n",
    "DF_predict =  model.predict( x_DF )  \n",
    "DF[model_name] =  np.transpose(DF_predict)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>STATE_CODE</th>\n",
       "      <th>re_CAL_P</th>\n",
       "      <th>...</th>\n",
       "      <th>re_ERA5_cape_Ci_box(7, 7)</th>\n",
       "      <th>re_ERA5_t2m_Ci_box(7, 7)</th>\n",
       "      <th>re_ERA5_tcw_Ci_box(7, 7)</th>\n",
       "      <th>re_CAL_P_Cj_box(7, 7)</th>\n",
       "      <th>re_PDIR_Cj_box(7, 7)</th>\n",
       "      <th>re_ERA5_tp_Cj_box(7, 7)</th>\n",
       "      <th>re_ERA5_cape_Cj_box(7, 7)</th>\n",
       "      <th>re_ERA5_t2m_Cj_box(7, 7)</th>\n",
       "      <th>re_ERA5_tcw_Cj_box(7, 7)</th>\n",
       "      <th>CNN7C_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'ADELAIDE INTERNATIONAL'</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4</td>\n",
       "      <td>6.068118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840210</td>\n",
       "      <td>-1.944682</td>\n",
       "      <td>0.599135</td>\n",
       "      <td>-0.699586</td>\n",
       "      <td>0.472380</td>\n",
       "      <td>-0.123873</td>\n",
       "      <td>0.088847</td>\n",
       "      <td>1.506138</td>\n",
       "      <td>-0.312740</td>\n",
       "      <td>5.413618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'ADELAIDE INTERNATIONAL'</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.296858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831268</td>\n",
       "      <td>-1.010901</td>\n",
       "      <td>-0.695603</td>\n",
       "      <td>-0.572087</td>\n",
       "      <td>0.484517</td>\n",
       "      <td>-0.028162</td>\n",
       "      <td>-0.344329</td>\n",
       "      <td>-0.216186</td>\n",
       "      <td>0.757789</td>\n",
       "      <td>1.902712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'ADELAIDE INTERNATIONAL'</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.317747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118344</td>\n",
       "      <td>-0.053611</td>\n",
       "      <td>-0.117902</td>\n",
       "      <td>0.655348</td>\n",
       "      <td>-0.087037</td>\n",
       "      <td>-0.270864</td>\n",
       "      <td>0.095703</td>\n",
       "      <td>0.169255</td>\n",
       "      <td>-0.056705</td>\n",
       "      <td>0.154283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'ADELAIDE INTERNATIONAL'</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.207015</td>\n",
       "      <td>...</td>\n",
       "      <td>1.061607</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.850361</td>\n",
       "      <td>-0.087037</td>\n",
       "      <td>-0.558607</td>\n",
       "      <td>0.065318</td>\n",
       "      <td>0.035855</td>\n",
       "      <td>-0.270147</td>\n",
       "      <td>0.251697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'ADELAIDE INTERNATIONAL'</td>\n",
       "      <td>94672099999</td>\n",
       "      <td>-34.945000</td>\n",
       "      <td>138.530556</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.40</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.317747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262106</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.167468</td>\n",
       "      <td>0.547893</td>\n",
       "      <td>-0.087037</td>\n",
       "      <td>-0.266987</td>\n",
       "      <td>0.392697</td>\n",
       "      <td>0.243836</td>\n",
       "      <td>0.231192</td>\n",
       "      <td>0.311486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512030</th>\n",
       "      <td>b'DALWALLINU COMPARISON'</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.240688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424571</td>\n",
       "      <td>0.525471</td>\n",
       "      <td>0.538855</td>\n",
       "      <td>0.057720</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>0.167523</td>\n",
       "      <td>0.272354</td>\n",
       "      <td>0.185373</td>\n",
       "      <td>-1.174151</td>\n",
       "      <td>0.148408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512031</th>\n",
       "      <td>b'DALWALLINU COMPARISON'</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.240688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424571</td>\n",
       "      <td>-0.787749</td>\n",
       "      <td>0.278295</td>\n",
       "      <td>0.057720</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>0.167523</td>\n",
       "      <td>0.272354</td>\n",
       "      <td>1.964685</td>\n",
       "      <td>-0.691088</td>\n",
       "      <td>0.266261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512032</th>\n",
       "      <td>b'DALWALLINU COMPARISON'</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.240688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424571</td>\n",
       "      <td>-1.687723</td>\n",
       "      <td>-1.868000</td>\n",
       "      <td>0.057720</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>0.167523</td>\n",
       "      <td>0.272354</td>\n",
       "      <td>0.949215</td>\n",
       "      <td>1.178577</td>\n",
       "      <td>0.509891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512033</th>\n",
       "      <td>b'DALWALLINU COMPARISON'</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.240688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424571</td>\n",
       "      <td>-1.547030</td>\n",
       "      <td>-1.614211</td>\n",
       "      <td>0.057720</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>0.167523</td>\n",
       "      <td>0.272354</td>\n",
       "      <td>0.154798</td>\n",
       "      <td>0.149776</td>\n",
       "      <td>0.364636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512034</th>\n",
       "      <td>b'DALWALLINU COMPARISON'</td>\n",
       "      <td>94619099999</td>\n",
       "      <td>-30.283333</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.240688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424571</td>\n",
       "      <td>0.045641</td>\n",
       "      <td>0.490150</td>\n",
       "      <td>0.057720</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>0.167523</td>\n",
       "      <td>0.272354</td>\n",
       "      <td>-0.407891</td>\n",
       "      <td>-2.952903</td>\n",
       "      <td>0.071304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512035 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              NAME      STATION   LATITUDE   LONGITUDE  YEAR  \\\n",
       "0        b'ADELAIDE INTERNATIONAL'  94672099999 -34.945000  138.530556  2014   \n",
       "1        b'ADELAIDE INTERNATIONAL'  94672099999 -34.945000  138.530556  2014   \n",
       "2        b'ADELAIDE INTERNATIONAL'  94672099999 -34.945000  138.530556  2014   \n",
       "3        b'ADELAIDE INTERNATIONAL'  94672099999 -34.945000  138.530556  2014   \n",
       "4        b'ADELAIDE INTERNATIONAL'  94672099999 -34.945000  138.530556  2014   \n",
       "...                            ...          ...        ...         ...   ...   \n",
       "1512030   b'DALWALLINU COMPARISON'  94619099999 -30.283333  116.666667  2024   \n",
       "1512031   b'DALWALLINU COMPARISON'  94619099999 -30.283333  116.666667  2024   \n",
       "1512032   b'DALWALLINU COMPARISON'  94619099999 -30.283333  116.666667  2024   \n",
       "1512033   b'DALWALLINU COMPARISON'  94619099999 -30.283333  116.666667  2024   \n",
       "1512034   b'DALWALLINU COMPARISON'  94619099999 -30.283333  116.666667  2024   \n",
       "\n",
       "         MONTH  DAY  PRCP  STATE_CODE  re_CAL_P  ...  \\\n",
       "0            1    1  4.56           4  6.068118  ...   \n",
       "1            1    2  1.44           4 -0.296858  ...   \n",
       "2            1    3  0.24           4 -0.317747  ...   \n",
       "3            1    4  0.00           4 -0.207015  ...   \n",
       "4            1    5  2.40           4 -0.317747  ...   \n",
       "...        ...  ...   ...         ...       ...  ...   \n",
       "1512030      1   27  0.00           5 -0.240688  ...   \n",
       "1512031      1   28  0.00           5 -0.240688  ...   \n",
       "1512032      1   29  0.00           5 -0.240688  ...   \n",
       "1512033      1   30  0.00           5 -0.240688  ...   \n",
       "1512034      1   31  0.00           5 -0.240688  ...   \n",
       "\n",
       "         re_ERA5_cape_Ci_box(7, 7)  re_ERA5_t2m_Ci_box(7, 7)  \\\n",
       "0                         0.840210                 -1.944682   \n",
       "1                         0.831268                 -1.010901   \n",
       "2                        -0.118344                 -0.053611   \n",
       "3                         1.061607                  0.147727   \n",
       "4                         0.262106                 -0.011495   \n",
       "...                            ...                       ...   \n",
       "1512030                  -0.424571                  0.525471   \n",
       "1512031                  -0.424571                 -0.787749   \n",
       "1512032                  -0.424571                 -1.687723   \n",
       "1512033                  -0.424571                 -1.547030   \n",
       "1512034                  -0.424571                  0.045641   \n",
       "\n",
       "         re_ERA5_tcw_Ci_box(7, 7)  re_CAL_P_Cj_box(7, 7)  \\\n",
       "0                        0.599135              -0.699586   \n",
       "1                       -0.695603              -0.572087   \n",
       "2                       -0.117902               0.655348   \n",
       "3                        0.902388               0.850361   \n",
       "4                        0.167468               0.547893   \n",
       "...                           ...                    ...   \n",
       "1512030                  0.538855               0.057720   \n",
       "1512031                  0.278295               0.057720   \n",
       "1512032                 -1.868000               0.057720   \n",
       "1512033                 -1.614211               0.057720   \n",
       "1512034                  0.490150               0.057720   \n",
       "\n",
       "         re_PDIR_Cj_box(7, 7)  re_ERA5_tp_Cj_box(7, 7)  \\\n",
       "0                    0.472380                -0.123873   \n",
       "1                    0.484517                -0.028162   \n",
       "2                   -0.087037                -0.270864   \n",
       "3                   -0.087037                -0.558607   \n",
       "4                   -0.087037                -0.266987   \n",
       "...                       ...                      ...   \n",
       "1512030              0.022655                 0.167523   \n",
       "1512031              0.022655                 0.167523   \n",
       "1512032              0.022655                 0.167523   \n",
       "1512033              0.022655                 0.167523   \n",
       "1512034              0.022655                 0.167523   \n",
       "\n",
       "         re_ERA5_cape_Cj_box(7, 7)  re_ERA5_t2m_Cj_box(7, 7)  \\\n",
       "0                         0.088847                  1.506138   \n",
       "1                        -0.344329                 -0.216186   \n",
       "2                         0.095703                  0.169255   \n",
       "3                         0.065318                  0.035855   \n",
       "4                         0.392697                  0.243836   \n",
       "...                            ...                       ...   \n",
       "1512030                   0.272354                  0.185373   \n",
       "1512031                   0.272354                  1.964685   \n",
       "1512032                   0.272354                  0.949215   \n",
       "1512033                   0.272354                  0.154798   \n",
       "1512034                   0.272354                 -0.407891   \n",
       "\n",
       "         re_ERA5_tcw_Cj_box(7, 7)  CNN7C_re  \n",
       "0                       -0.312740  5.413618  \n",
       "1                        0.757789  1.902712  \n",
       "2                       -0.056705  0.154283  \n",
       "3                       -0.270147  0.251697  \n",
       "4                        0.231192  0.311486  \n",
       "...                           ...       ...  \n",
       "1512030                 -1.174151  0.148408  \n",
       "1512031                 -0.691088  0.266261  \n",
       "1512032                  1.178577  0.509891  \n",
       "1512033                  0.149776  0.364636  \n",
       "1512034                 -2.952903  0.071304  \n",
       "\n",
       "[1512035 rows x 88 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the model in parent Data Frame \n",
    "\n",
    "model_name = 'CNN7c_re'\n",
    "x_DF = Reshape(X_DF)\n",
    "DF_predict =  model.predict( x_DF )  \n",
    "DF[model_name] =  np.transpose(DF_predict)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the CNN model in hdf format\n",
    "\n",
    "model_name = 'CNN7'\n",
    "model.save(  '../models-2/' + model_name + '.keras' )\n",
    "Params['name']  = model_name \n",
    "Params['ord_keys']  = ord_Keys\n",
    "Dict_to_hdf( Dict= Params  , of = '../models-2/' + model_name + '.hdf5' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S4055367\\AppData\\Local\\Temp\\ipykernel_2088\\3611960376.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['train'][model_name] = predicted_train\n",
      "C:\\Users\\S4055367\\AppData\\Local\\Temp\\ipykernel_2088\\3611960376.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['train'][model_name] = predicted_train\n",
      "C:\\Users\\S4055367\\AppData\\Local\\Temp\\ipykernel_2088\\3611960376.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['test'][model_name] = predicted_test\n",
      "C:\\Users\\S4055367\\AppData\\Local\\Temp\\ipykernel_2088\\3611960376.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['test'][model_name] = predicted_test\n"
     ]
    }
   ],
   "source": [
    "# Save model prediction for train and test  dataframes\n",
    "\n",
    "df['train'][model_name] = predicted_train\n",
    "\n",
    "df['test'][model_name] = predicted_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42670462361179085"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef( np.array(df['test']['GSMAP']  ) , obs_test )[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM , Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S4055367\\AppData\\Local\\anaconda3\\envs\\ML\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_91 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m5,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_92 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_93 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_94 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_28 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m161\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,369</span> (118.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,369\u001b[0m (118.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,369</span> (118.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,369\u001b[0m (118.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - loss: 50.4610\n",
      "Epoch 2/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - loss: 30.7862\n",
      "Epoch 3/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 29.0489\n",
      "Epoch 4/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 103ms/step - loss: 27.9303\n",
      "Epoch 5/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - loss: 27.6507\n",
      "Epoch 6/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - loss: 27.8414\n",
      "Epoch 7/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 389ms/step - loss: 26.6539\n",
      "Epoch 8/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 412ms/step - loss: 26.9637\n",
      "Epoch 9/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - loss: 26.2253\n",
      "Epoch 10/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 123ms/step - loss: 26.8036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22ef21a1a90>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Params = {   \n",
    "    'layers': [32]*4,\n",
    "    'activation_function'  : ['relu'] *4,\n",
    "    'n_epoch': 10,\n",
    "    'size_batch' : 10000,\n",
    "    'Optimizer' : 'adam'\n",
    " }\n",
    "\n",
    "model_name = 'LSTM_RA_4(-4)'\n",
    "\n",
    "\n",
    "\n",
    "x_train =  Reshape(X_train)\n",
    "x_test  = Reshape(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(Params['layers'][0] ,return_sequences=True, activation= Params['activation_function'][0], input_shape= (x_train.shape[1]  ,x_train.shape[2]   ))) # input_shape=( x_train.shape[1]  , 1)\n",
    "for i in range(len(Params['layers'])-1) :\n",
    "    model.add(LSTM(Params['layers'][i+1],activation=Params['activation_function'][i+1], return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss= 'mse'  , optimizer=Params['Optimizer'] )\n",
    "model.summary()\n",
    "model.fit(x_train,obs_train, epochs=Params['n_epoch'], batch_size = Params['size_batch'], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15569/15569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step\n",
      "\u001b[1m31683/31683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.699093522623383"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "y_test = model.predict(x_test)\n",
    "predicted_test = numpy.transpose(y_test)[0]\n",
    "\n",
    "y_train = model.predict(x_train)\n",
    "predicted_train = numpy.transpose(y_train)[0]\n",
    "\n",
    "np.corrcoef( predicted_test  , obs_test )[0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S4055367\\AppData\\Local\\Temp\\ipykernel_18996\\953005878.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['train'][model_name] = predicted_train\n",
      "C:\\Users\\S4055367\\AppData\\Local\\Temp\\ipykernel_18996\\953005878.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['test'][model_name] = predicted_test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['train'][model_name] = predicted_train\n",
    "\n",
    "df['test'][model_name] = predicted_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Params['name']  = model_name \n",
    "Params['ord_keys']  = ord_Keys\n",
    "Params['input_shape']  = (x_test.shape[1]  ,  x_test.shape[2])\n",
    "model.save(  '../models/' + model_name + '.keras' )\n",
    "Dict_to_hdf( Dict= Params  , of = '../models/' + model_name + '.hdf5' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xx</th>\n",
       "      <th>LSTM_RA_3(-4)</th>\n",
       "      <th>LSTM_RA_3(-3)</th>\n",
       "      <th>LSTM_RA_3(-2)</th>\n",
       "      <th>LSTM_RA_3(-1)</th>\n",
       "      <th>LSTM_RA_3</th>\n",
       "      <th>LSTM_RA_2</th>\n",
       "      <th>LSTM_RA_1</th>\n",
       "      <th>LSTM_RA_0(-4)</th>\n",
       "      <th>LSTM_RA_0(-3)</th>\n",
       "      <th>LSTM_RA_0(-2)</th>\n",
       "      <th>LSTM_RA_0(-1)</th>\n",
       "      <th>LSTM_RA_0</th>\n",
       "      <th>CAL_P</th>\n",
       "      <th>PDIR</th>\n",
       "      <th>ERA5_tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.695017</td>\n",
       "      <td>0.688238</td>\n",
       "      <td>0.687358</td>\n",
       "      <td>0.687914</td>\n",
       "      <td>0.684286</td>\n",
       "      <td>0.681156</td>\n",
       "      <td>0.676202</td>\n",
       "      <td>0.67013</td>\n",
       "      <td>0.669516</td>\n",
       "      <td>0.670181</td>\n",
       "      <td>0.673875</td>\n",
       "      <td>0.668659</td>\n",
       "      <td>0.662532</td>\n",
       "      <td>0.568148</td>\n",
       "      <td>0.389067</td>\n",
       "      <td>0.596399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSE</th>\n",
       "      <td>0.479301</td>\n",
       "      <td>0.473031</td>\n",
       "      <td>0.469537</td>\n",
       "      <td>0.4713</td>\n",
       "      <td>0.464568</td>\n",
       "      <td>0.463304</td>\n",
       "      <td>0.453689</td>\n",
       "      <td>0.445462</td>\n",
       "      <td>0.445964</td>\n",
       "      <td>0.445694</td>\n",
       "      <td>0.44407</td>\n",
       "      <td>0.446987</td>\n",
       "      <td>0.433499</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>-0.384067</td>\n",
       "      <td>-0.067623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>5.926557</td>\n",
       "      <td>5.962132</td>\n",
       "      <td>5.981868</td>\n",
       "      <td>5.971917</td>\n",
       "      <td>6.009818</td>\n",
       "      <td>6.016908</td>\n",
       "      <td>6.070563</td>\n",
       "      <td>6.116103</td>\n",
       "      <td>6.113335</td>\n",
       "      <td>6.114821</td>\n",
       "      <td>6.123771</td>\n",
       "      <td>6.107686</td>\n",
       "      <td>6.181722</td>\n",
       "      <td>8.198091</td>\n",
       "      <td>9.662458</td>\n",
       "      <td>8.486294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.79198</td>\n",
       "      <td>1.916276</td>\n",
       "      <td>1.74619</td>\n",
       "      <td>1.864187</td>\n",
       "      <td>1.886338</td>\n",
       "      <td>1.84893</td>\n",
       "      <td>1.818721</td>\n",
       "      <td>1.888484</td>\n",
       "      <td>1.907056</td>\n",
       "      <td>1.848605</td>\n",
       "      <td>1.819043</td>\n",
       "      <td>1.89292</td>\n",
       "      <td>1.819593</td>\n",
       "      <td>2.501195</td>\n",
       "      <td>2.750997</td>\n",
       "      <td>2.136513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MBE</th>\n",
       "      <td>-0.155089</td>\n",
       "      <td>0.128794</td>\n",
       "      <td>-0.163835</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>0.142905</td>\n",
       "      <td>-0.057732</td>\n",
       "      <td>-0.13561</td>\n",
       "      <td>-0.058049</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>-0.21955</td>\n",
       "      <td>-0.255901</td>\n",
       "      <td>0.041147</td>\n",
       "      <td>-0.255838</td>\n",
       "      <td>0.478239</td>\n",
       "      <td>0.06976</td>\n",
       "      <td>-2.136476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PBIAS</th>\n",
       "      <td>-7.258754</td>\n",
       "      <td>6.028073</td>\n",
       "      <td>-7.668128</td>\n",
       "      <td>0.642011</td>\n",
       "      <td>6.688521</td>\n",
       "      <td>-2.702062</td>\n",
       "      <td>-6.347088</td>\n",
       "      <td>-2.716919</td>\n",
       "      <td>4.900371</td>\n",
       "      <td>-10.275775</td>\n",
       "      <td>-11.97717</td>\n",
       "      <td>1.925849</td>\n",
       "      <td>-11.974236</td>\n",
       "      <td>22.383457</td>\n",
       "      <td>3.265023</td>\n",
       "      <td>-99.995429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KGE</th>\n",
       "      <td>0.520198</td>\n",
       "      <td>0.540873</td>\n",
       "      <td>0.584711</td>\n",
       "      <td>0.526571</td>\n",
       "      <td>0.587069</td>\n",
       "      <td>0.530371</td>\n",
       "      <td>0.495882</td>\n",
       "      <td>0.488818</td>\n",
       "      <td>0.561263</td>\n",
       "      <td>0.484885</td>\n",
       "      <td>0.453894</td>\n",
       "      <td>0.537788</td>\n",
       "      <td>0.459853</td>\n",
       "      <td>0.496499</td>\n",
       "      <td>0.376392</td>\n",
       "      <td>-0.470622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman</th>\n",
       "      <td>0.636628</td>\n",
       "      <td>0.643502</td>\n",
       "      <td>0.644044</td>\n",
       "      <td>0.655364</td>\n",
       "      <td>0.635195</td>\n",
       "      <td>0.639702</td>\n",
       "      <td>0.639726</td>\n",
       "      <td>0.622778</td>\n",
       "      <td>0.643303</td>\n",
       "      <td>0.644665</td>\n",
       "      <td>0.642815</td>\n",
       "      <td>0.645777</td>\n",
       "      <td>0.628409</td>\n",
       "      <td>0.491643</td>\n",
       "      <td>0.394756</td>\n",
       "      <td>0.628714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.22999</td>\n",
       "      <td>5.48954</td>\n",
       "      <td>6.058218</td>\n",
       "      <td>5.289711</td>\n",
       "      <td>6.097355</td>\n",
       "      <td>5.389923</td>\n",
       "      <td>5.08285</td>\n",
       "      <td>5.013648</td>\n",
       "      <td>5.877529</td>\n",
       "      <td>5.074859</td>\n",
       "      <td>4.752594</td>\n",
       "      <td>5.571073</td>\n",
       "      <td>4.891781</td>\n",
       "      <td>9.281308</td>\n",
       "      <td>9.20492</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obs_std</th>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "      <td>8.213137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_heavy</th>\n",
       "      <td>0.402837</td>\n",
       "      <td>0.366487</td>\n",
       "      <td>0.362405</td>\n",
       "      <td>0.363875</td>\n",
       "      <td>0.381857</td>\n",
       "      <td>0.361563</td>\n",
       "      <td>0.316789</td>\n",
       "      <td>0.304475</td>\n",
       "      <td>0.330037</td>\n",
       "      <td>0.419826</td>\n",
       "      <td>0.428864</td>\n",
       "      <td>0.34063</td>\n",
       "      <td>0.357449</td>\n",
       "      <td>0.321074</td>\n",
       "      <td>0.245752</td>\n",
       "      <td>0.332921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSE_heavy</th>\n",
       "      <td>-3.423709</td>\n",
       "      <td>-3.493719</td>\n",
       "      <td>-2.962708</td>\n",
       "      <td>-3.540127</td>\n",
       "      <td>-3.002449</td>\n",
       "      <td>-3.458097</td>\n",
       "      <td>-4.014662</td>\n",
       "      <td>-4.188285</td>\n",
       "      <td>-3.530115</td>\n",
       "      <td>-3.583058</td>\n",
       "      <td>-4.091741</td>\n",
       "      <td>-3.633166</td>\n",
       "      <td>-4.033886</td>\n",
       "      <td>-2.366826</td>\n",
       "      <td>-4.34352</td>\n",
       "      <td>-8.690413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE_heavy</th>\n",
       "      <td>101.736795</td>\n",
       "      <td>102.538684</td>\n",
       "      <td>96.289924</td>\n",
       "      <td>103.066801</td>\n",
       "      <td>96.771548</td>\n",
       "      <td>102.131461</td>\n",
       "      <td>108.319246</td>\n",
       "      <td>110.178464</td>\n",
       "      <td>102.953092</td>\n",
       "      <td>103.552942</td>\n",
       "      <td>109.148546</td>\n",
       "      <td>104.117494</td>\n",
       "      <td>108.526665</td>\n",
       "      <td>88.755468</td>\n",
       "      <td>111.814595</td>\n",
       "      <td>150.57606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE_heavy</th>\n",
       "      <td>90.903359</td>\n",
       "      <td>91.490579</td>\n",
       "      <td>83.875592</td>\n",
       "      <td>91.93019</td>\n",
       "      <td>84.711594</td>\n",
       "      <td>90.605266</td>\n",
       "      <td>97.718343</td>\n",
       "      <td>99.857353</td>\n",
       "      <td>91.907491</td>\n",
       "      <td>93.438032</td>\n",
       "      <td>99.976461</td>\n",
       "      <td>93.694819</td>\n",
       "      <td>98.424427</td>\n",
       "      <td>73.962012</td>\n",
       "      <td>95.5456</td>\n",
       "      <td>142.595434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MBE_heavy</th>\n",
       "      <td>-90.896063</td>\n",
       "      <td>-91.456145</td>\n",
       "      <td>-83.22291</td>\n",
       "      <td>-91.851853</td>\n",
       "      <td>-84.394538</td>\n",
       "      <td>-90.54822</td>\n",
       "      <td>-97.697161</td>\n",
       "      <td>-99.857353</td>\n",
       "      <td>-91.619893</td>\n",
       "      <td>-93.328411</td>\n",
       "      <td>-99.976461</td>\n",
       "      <td>-93.122737</td>\n",
       "      <td>-98.305995</td>\n",
       "      <td>-62.77035</td>\n",
       "      <td>-80.686756</td>\n",
       "      <td>-142.595434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PBIAS_heavy</th>\n",
       "      <td>-63.742933</td>\n",
       "      <td>-64.135703</td>\n",
       "      <td>-58.36196</td>\n",
       "      <td>-64.413203</td>\n",
       "      <td>-59.183591</td>\n",
       "      <td>-63.499001</td>\n",
       "      <td>-68.512358</td>\n",
       "      <td>-70.027242</td>\n",
       "      <td>-64.250536</td>\n",
       "      <td>-65.448673</td>\n",
       "      <td>-70.110769</td>\n",
       "      <td>-65.304439</td>\n",
       "      <td>-68.939317</td>\n",
       "      <td>-44.019137</td>\n",
       "      <td>-56.583424</td>\n",
       "      <td>-99.998294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KGE_heavy</th>\n",
       "      <td>0.054094</td>\n",
       "      <td>0.012588</td>\n",
       "      <td>0.093932</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.094664</td>\n",
       "      <td>0.034801</td>\n",
       "      <td>-0.086572</td>\n",
       "      <td>-0.13326</td>\n",
       "      <td>-0.028664</td>\n",
       "      <td>0.042843</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>-0.032375</td>\n",
       "      <td>-0.051201</td>\n",
       "      <td>0.164652</td>\n",
       "      <td>-0.076347</td>\n",
       "      <td>-0.563613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_heavy</th>\n",
       "      <td>0.333493</td>\n",
       "      <td>0.275201</td>\n",
       "      <td>0.285475</td>\n",
       "      <td>0.285486</td>\n",
       "      <td>0.299875</td>\n",
       "      <td>0.295891</td>\n",
       "      <td>0.273651</td>\n",
       "      <td>0.289071</td>\n",
       "      <td>0.296287</td>\n",
       "      <td>0.330496</td>\n",
       "      <td>0.330198</td>\n",
       "      <td>0.313718</td>\n",
       "      <td>0.306711</td>\n",
       "      <td>0.29487</td>\n",
       "      <td>0.284163</td>\n",
       "      <td>0.24192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_obs_heavy</th>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "      <td>48.370969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_model_heavy</th>\n",
       "      <td>30.809027</td>\n",
       "      <td>28.883682</td>\n",
       "      <td>35.228592</td>\n",
       "      <td>30.092878</td>\n",
       "      <td>34.082115</td>\n",
       "      <td>31.559458</td>\n",
       "      <td>24.454617</td>\n",
       "      <td>21.432961</td>\n",
       "      <td>26.929646</td>\n",
       "      <td>29.562571</td>\n",
       "      <td>23.693768</td>\n",
       "      <td>26.49342</td>\n",
       "      <td>25.843945</td>\n",
       "      <td>58.412689</td>\n",
       "      <td>73.480314</td>\n",
       "      <td>0.001824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_ext</th>\n",
       "      <td>0.459338</td>\n",
       "      <td>0.438026</td>\n",
       "      <td>0.443065</td>\n",
       "      <td>0.447818</td>\n",
       "      <td>0.451019</td>\n",
       "      <td>0.445077</td>\n",
       "      <td>0.403449</td>\n",
       "      <td>0.388368</td>\n",
       "      <td>0.406404</td>\n",
       "      <td>0.462194</td>\n",
       "      <td>0.457922</td>\n",
       "      <td>0.409176</td>\n",
       "      <td>0.431503</td>\n",
       "      <td>0.407156</td>\n",
       "      <td>0.31304</td>\n",
       "      <td>0.346135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSE_ext</th>\n",
       "      <td>-1.804488</td>\n",
       "      <td>-1.781403</td>\n",
       "      <td>-1.494369</td>\n",
       "      <td>-1.858695</td>\n",
       "      <td>-1.517129</td>\n",
       "      <td>-1.814791</td>\n",
       "      <td>-2.075617</td>\n",
       "      <td>-2.156427</td>\n",
       "      <td>-1.740517</td>\n",
       "      <td>-1.94827</td>\n",
       "      <td>-2.19272</td>\n",
       "      <td>-1.857111</td>\n",
       "      <td>-2.174039</td>\n",
       "      <td>-1.406075</td>\n",
       "      <td>-2.739546</td>\n",
       "      <td>-5.39561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE_ext</th>\n",
       "      <td>66.4662</td>\n",
       "      <td>66.19207</td>\n",
       "      <td>62.68367</td>\n",
       "      <td>67.105477</td>\n",
       "      <td>62.969002</td>\n",
       "      <td>66.58818</td>\n",
       "      <td>69.604959</td>\n",
       "      <td>70.513446</td>\n",
       "      <td>65.703766</td>\n",
       "      <td>68.14871</td>\n",
       "      <td>70.917672</td>\n",
       "      <td>67.086877</td>\n",
       "      <td>70.709895</td>\n",
       "      <td>61.564252</td>\n",
       "      <td>76.750896</td>\n",
       "      <td>100.372563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE_ext</th>\n",
       "      <td>56.545948</td>\n",
       "      <td>56.038838</td>\n",
       "      <td>52.032892</td>\n",
       "      <td>57.225746</td>\n",
       "      <td>52.48635</td>\n",
       "      <td>56.433175</td>\n",
       "      <td>59.345837</td>\n",
       "      <td>60.299028</td>\n",
       "      <td>55.008378</td>\n",
       "      <td>58.914789</td>\n",
       "      <td>61.789451</td>\n",
       "      <td>57.002697</td>\n",
       "      <td>61.141576</td>\n",
       "      <td>49.884181</td>\n",
       "      <td>64.604926</td>\n",
       "      <td>92.192452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MBE_ext</th>\n",
       "      <td>-55.930289</td>\n",
       "      <td>-55.390174</td>\n",
       "      <td>-50.40554</td>\n",
       "      <td>-56.592061</td>\n",
       "      <td>-51.118171</td>\n",
       "      <td>-55.774462</td>\n",
       "      <td>-59.193119</td>\n",
       "      <td>-60.172498</td>\n",
       "      <td>-54.362611</td>\n",
       "      <td>-58.030268</td>\n",
       "      <td>-61.496842</td>\n",
       "      <td>-56.047848</td>\n",
       "      <td>-60.820807</td>\n",
       "      <td>-39.534171</td>\n",
       "      <td>-52.703391</td>\n",
       "      <td>-92.192452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PBIAS_ext</th>\n",
       "      <td>-60.665718</td>\n",
       "      <td>-60.079873</td>\n",
       "      <td>-54.673206</td>\n",
       "      <td>-61.38352</td>\n",
       "      <td>-55.446173</td>\n",
       "      <td>-60.496697</td>\n",
       "      <td>-64.2048</td>\n",
       "      <td>-65.2671</td>\n",
       "      <td>-58.965309</td>\n",
       "      <td>-62.943494</td>\n",
       "      <td>-66.703571</td>\n",
       "      <td>-60.79323</td>\n",
       "      <td>-65.970298</td>\n",
       "      <td>-42.881396</td>\n",
       "      <td>-57.165608</td>\n",
       "      <td>-99.998075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KGE_ext</th>\n",
       "      <td>0.107723</td>\n",
       "      <td>0.084368</td>\n",
       "      <td>0.171501</td>\n",
       "      <td>0.086629</td>\n",
       "      <td>0.163853</td>\n",
       "      <td>0.103699</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>-0.03371</td>\n",
       "      <td>0.063112</td>\n",
       "      <td>0.088012</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.055401</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>0.249174</td>\n",
       "      <td>0.040392</td>\n",
       "      <td>-0.55802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_ext</th>\n",
       "      <td>0.347133</td>\n",
       "      <td>0.345878</td>\n",
       "      <td>0.349533</td>\n",
       "      <td>0.347353</td>\n",
       "      <td>0.342445</td>\n",
       "      <td>0.341683</td>\n",
       "      <td>0.328803</td>\n",
       "      <td>0.33253</td>\n",
       "      <td>0.342814</td>\n",
       "      <td>0.354753</td>\n",
       "      <td>0.345408</td>\n",
       "      <td>0.347643</td>\n",
       "      <td>0.339031</td>\n",
       "      <td>0.315823</td>\n",
       "      <td>0.25269</td>\n",
       "      <td>0.273117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_obs_ext</th>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "      <td>39.689354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_model_ext</th>\n",
       "      <td>25.062881</td>\n",
       "      <td>23.734076</td>\n",
       "      <td>28.653364</td>\n",
       "      <td>24.187689</td>\n",
       "      <td>27.760502</td>\n",
       "      <td>25.410501</td>\n",
       "      <td>20.722706</td>\n",
       "      <td>19.12418</td>\n",
       "      <td>22.957886</td>\n",
       "      <td>24.508524</td>\n",
       "      <td>19.764065</td>\n",
       "      <td>23.152077</td>\n",
       "      <td>21.459206</td>\n",
       "      <td>46.37727</td>\n",
       "      <td>53.560365</td>\n",
       "      <td>0.001515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POD</th>\n",
       "      <td>0.858924</td>\n",
       "      <td>0.900438</td>\n",
       "      <td>0.778374</td>\n",
       "      <td>0.882169</td>\n",
       "      <td>0.860429</td>\n",
       "      <td>0.851106</td>\n",
       "      <td>0.850584</td>\n",
       "      <td>0.851409</td>\n",
       "      <td>0.854681</td>\n",
       "      <td>0.856092</td>\n",
       "      <td>0.844313</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.840508</td>\n",
       "      <td>0.619979</td>\n",
       "      <td>0.720179</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAR</th>\n",
       "      <td>0.430414</td>\n",
       "      <td>0.498758</td>\n",
       "      <td>0.377859</td>\n",
       "      <td>0.464744</td>\n",
       "      <td>0.448811</td>\n",
       "      <td>0.434572</td>\n",
       "      <td>0.427473</td>\n",
       "      <td>0.44072</td>\n",
       "      <td>0.450673</td>\n",
       "      <td>0.45056</td>\n",
       "      <td>0.440181</td>\n",
       "      <td>0.459744</td>\n",
       "      <td>0.43237</td>\n",
       "      <td>0.472814</td>\n",
       "      <td>0.629739</td>\n",
       "      <td>Undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIAS</th>\n",
       "      <td>1.50798</td>\n",
       "      <td>1.796413</td>\n",
       "      <td>1.251121</td>\n",
       "      <td>1.648126</td>\n",
       "      <td>1.561043</td>\n",
       "      <td>1.505241</td>\n",
       "      <td>1.485666</td>\n",
       "      <td>1.52233</td>\n",
       "      <td>1.555869</td>\n",
       "      <td>1.558116</td>\n",
       "      <td>1.508189</td>\n",
       "      <td>1.600466</td>\n",
       "      <td>1.480732</td>\n",
       "      <td>1.176016</td>\n",
       "      <td>1.945056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSI</th>\n",
       "      <td>0.520858</td>\n",
       "      <td>0.474921</td>\n",
       "      <td>0.528518</td>\n",
       "      <td>0.499541</td>\n",
       "      <td>0.505952</td>\n",
       "      <td>0.514532</td>\n",
       "      <td>0.520209</td>\n",
       "      <td>0.509545</td>\n",
       "      <td>0.502402</td>\n",
       "      <td>0.502984</td>\n",
       "      <td>0.507437</td>\n",
       "      <td>0.498133</td>\n",
       "      <td>0.512435</td>\n",
       "      <td>0.398435</td>\n",
       "      <td>0.323694</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POD_heavy</th>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.084444</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.071111</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.031111</td>\n",
       "      <td>0.308889</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAR_heavy</th>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.40566</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.747731</td>\n",
       "      <td>0.861272</td>\n",
       "      <td>Undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIAS_heavy</th>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.124444</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.235556</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.042222</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.131111</td>\n",
       "      <td>0.042222</td>\n",
       "      <td>0.091111</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>1.224444</td>\n",
       "      <td>1.537778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSI_heavy</th>\n",
       "      <td>0.075107</td>\n",
       "      <td>0.081197</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.067653</td>\n",
       "      <td>0.127789</td>\n",
       "      <td>0.092632</td>\n",
       "      <td>0.024017</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>0.060417</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.031513</td>\n",
       "      <td>0.030108</td>\n",
       "      <td>0.161253</td>\n",
       "      <td>0.091778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POD_ex</th>\n",
       "      <td>0.162085</td>\n",
       "      <td>0.148339</td>\n",
       "      <td>0.212486</td>\n",
       "      <td>0.143184</td>\n",
       "      <td>0.202749</td>\n",
       "      <td>0.160367</td>\n",
       "      <td>0.109966</td>\n",
       "      <td>0.093356</td>\n",
       "      <td>0.156357</td>\n",
       "      <td>0.134593</td>\n",
       "      <td>0.08362</td>\n",
       "      <td>0.15063</td>\n",
       "      <td>0.10882</td>\n",
       "      <td>0.318442</td>\n",
       "      <td>0.212486</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAR_ex</th>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.410023</td>\n",
       "      <td>0.500673</td>\n",
       "      <td>0.421296</td>\n",
       "      <td>0.509015</td>\n",
       "      <td>0.448819</td>\n",
       "      <td>0.405573</td>\n",
       "      <td>0.398524</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.473094</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.484314</td>\n",
       "      <td>0.41896</td>\n",
       "      <td>0.770058</td>\n",
       "      <td>0.804942</td>\n",
       "      <td>Undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIAS_ex</th>\n",
       "      <td>0.266896</td>\n",
       "      <td>0.251432</td>\n",
       "      <td>0.425544</td>\n",
       "      <td>0.247423</td>\n",
       "      <td>0.412944</td>\n",
       "      <td>0.290951</td>\n",
       "      <td>0.184994</td>\n",
       "      <td>0.155212</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0.255441</td>\n",
       "      <td>0.13173</td>\n",
       "      <td>0.292096</td>\n",
       "      <td>0.187285</td>\n",
       "      <td>1.38488</td>\n",
       "      <td>1.089347</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSI_ex</th>\n",
       "      <td>0.146708</td>\n",
       "      <td>0.134476</td>\n",
       "      <td>0.175165</td>\n",
       "      <td>0.129668</td>\n",
       "      <td>0.167534</td>\n",
       "      <td>0.141844</td>\n",
       "      <td>0.102291</td>\n",
       "      <td>0.087918</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.120082</td>\n",
       "      <td>0.079781</td>\n",
       "      <td>0.131962</td>\n",
       "      <td>0.100903</td>\n",
       "      <td>0.154102</td>\n",
       "      <td>0.113213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KS</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_value(t-test)</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         xx LSTM_RA_3(-4) LSTM_RA_3(-3) LSTM_RA_3(-2)  \\\n",
       "r                  0.695017      0.688238      0.687358      0.687914   \n",
       "NSE                0.479301      0.473031      0.469537        0.4713   \n",
       "RMSE               5.926557      5.962132      5.981868      5.971917   \n",
       "MAE                 1.79198      1.916276       1.74619      1.864187   \n",
       "MBE               -0.155089      0.128794     -0.163835      0.013717   \n",
       "PBIAS             -7.258754      6.028073     -7.668128      0.642011   \n",
       "KGE                0.520198      0.540873      0.584711      0.526571   \n",
       "spearman           0.636628      0.643502      0.644044      0.655364   \n",
       "std                 5.22999       5.48954      6.058218      5.289711   \n",
       "obs_std            8.213137      8.213137      8.213137      8.213137   \n",
       "r_heavy            0.402837      0.366487      0.362405      0.363875   \n",
       "NSE_heavy         -3.423709     -3.493719     -2.962708     -3.540127   \n",
       "RMSE_heavy       101.736795    102.538684     96.289924    103.066801   \n",
       "MAE_heavy         90.903359     91.490579     83.875592      91.93019   \n",
       "MBE_heavy        -90.896063    -91.456145     -83.22291    -91.851853   \n",
       "PBIAS_heavy      -63.742933    -64.135703     -58.36196    -64.413203   \n",
       "KGE_heavy          0.054094      0.012588      0.093932      0.019006   \n",
       "spearman_heavy     0.333493      0.275201      0.285475      0.285486   \n",
       "std_obs_heavy     48.370969     48.370969     48.370969     48.370969   \n",
       "std_model_heavy   30.809027     28.883682     35.228592     30.092878   \n",
       "r_ext              0.459338      0.438026      0.443065      0.447818   \n",
       "NSE_ext           -1.804488     -1.781403     -1.494369     -1.858695   \n",
       "RMSE_ext            66.4662      66.19207      62.68367     67.105477   \n",
       "MAE_ext           56.545948     56.038838     52.032892     57.225746   \n",
       "MBE_ext          -55.930289    -55.390174     -50.40554    -56.592061   \n",
       "PBIAS_ext        -60.665718    -60.079873    -54.673206     -61.38352   \n",
       "KGE_ext            0.107723      0.084368      0.171501      0.086629   \n",
       "spearman_ext       0.347133      0.345878      0.349533      0.347353   \n",
       "std_obs_ext       39.689354     39.689354     39.689354     39.689354   \n",
       "std_model_ext     25.062881     23.734076     28.653364     24.187689   \n",
       "POD                0.858924      0.900438      0.778374      0.882169   \n",
       "FAR                0.430414      0.498758      0.377859      0.464744   \n",
       "BIAS                1.50798      1.796413      1.251121      1.648126   \n",
       "CSI                0.520858      0.474921      0.528518      0.499541   \n",
       "POD_heavy          0.077778      0.084444          0.12      0.071111   \n",
       "FAR_heavy          0.313725      0.321429           0.5      0.418182   \n",
       "BIAS_heavy         0.113333      0.124444          0.24      0.122222   \n",
       "CSI_heavy          0.075107      0.081197      0.107143      0.067653   \n",
       "POD_ex             0.162085      0.148339      0.212486      0.143184   \n",
       "FAR_ex             0.392704      0.410023      0.500673      0.421296   \n",
       "BIAS_ex            0.266896      0.251432      0.425544      0.247423   \n",
       "CSI_ex             0.146708      0.134476      0.175165      0.129668   \n",
       "KS                     -1.0          -1.0          -1.0          -1.0   \n",
       "P_value(t-test)        None          None          None          None   \n",
       "\n",
       "                LSTM_RA_3(-1)   LSTM_RA_3   LSTM_RA_2   LSTM_RA_1  \\\n",
       "r                    0.684286    0.681156    0.676202     0.67013   \n",
       "NSE                  0.464568    0.463304    0.453689    0.445462   \n",
       "RMSE                 6.009818    6.016908    6.070563    6.116103   \n",
       "MAE                  1.886338     1.84893    1.818721    1.888484   \n",
       "MBE                  0.142905   -0.057732    -0.13561   -0.058049   \n",
       "PBIAS                6.688521   -2.702062   -6.347088   -2.716919   \n",
       "KGE                  0.587069    0.530371    0.495882    0.488818   \n",
       "spearman             0.635195    0.639702    0.639726    0.622778   \n",
       "std                  6.097355    5.389923     5.08285    5.013648   \n",
       "obs_std              8.213137    8.213137    8.213137    8.213137   \n",
       "r_heavy              0.381857    0.361563    0.316789    0.304475   \n",
       "NSE_heavy           -3.002449   -3.458097   -4.014662   -4.188285   \n",
       "RMSE_heavy          96.771548  102.131461  108.319246  110.178464   \n",
       "MAE_heavy           84.711594   90.605266   97.718343   99.857353   \n",
       "MBE_heavy          -84.394538   -90.54822  -97.697161  -99.857353   \n",
       "PBIAS_heavy        -59.183591  -63.499001  -68.512358  -70.027242   \n",
       "KGE_heavy            0.094664    0.034801   -0.086572    -0.13326   \n",
       "spearman_heavy       0.299875    0.295891    0.273651    0.289071   \n",
       "std_obs_heavy       48.370969   48.370969   48.370969   48.370969   \n",
       "std_model_heavy     34.082115   31.559458   24.454617   21.432961   \n",
       "r_ext                0.451019    0.445077    0.403449    0.388368   \n",
       "NSE_ext             -1.517129   -1.814791   -2.075617   -2.156427   \n",
       "RMSE_ext            62.969002    66.58818   69.604959   70.513446   \n",
       "MAE_ext              52.48635   56.433175   59.345837   60.299028   \n",
       "MBE_ext            -51.118171  -55.774462  -59.193119  -60.172498   \n",
       "PBIAS_ext          -55.446173  -60.496697    -64.2048    -65.2671   \n",
       "KGE_ext              0.163853    0.103699    0.001769    -0.03371   \n",
       "spearman_ext         0.342445    0.341683    0.328803     0.33253   \n",
       "std_obs_ext         39.689354   39.689354   39.689354   39.689354   \n",
       "std_model_ext       27.760502   25.410501   20.722706    19.12418   \n",
       "POD                  0.860429    0.851106    0.850584    0.851409   \n",
       "FAR                  0.448811    0.434572    0.427473     0.44072   \n",
       "BIAS                 1.561043    1.505241    1.485666     1.52233   \n",
       "CSI                  0.505952    0.514532    0.520209    0.509545   \n",
       "POD_heavy                0.14    0.097778    0.024444    0.004444   \n",
       "FAR_heavy             0.40566    0.362319    0.421053    0.714286   \n",
       "BIAS_heavy           0.235556    0.153333    0.042222    0.015556   \n",
       "CSI_heavy            0.127789    0.092632    0.024017    0.004396   \n",
       "POD_ex               0.202749    0.160367    0.109966    0.093356   \n",
       "FAR_ex               0.509015    0.448819    0.405573    0.398524   \n",
       "BIAS_ex              0.412944    0.290951    0.184994    0.155212   \n",
       "CSI_ex               0.167534    0.141844    0.102291    0.087918   \n",
       "KS                       -1.0        -1.0        -1.0        -1.0   \n",
       "P_value(t-test)          None        None        None        None   \n",
       "\n",
       "                LSTM_RA_0(-4) LSTM_RA_0(-3) LSTM_RA_0(-2) LSTM_RA_0(-1)  \\\n",
       "r                    0.669516      0.670181      0.673875      0.668659   \n",
       "NSE                  0.445964      0.445694       0.44407      0.446987   \n",
       "RMSE                 6.113335      6.114821      6.123771      6.107686   \n",
       "MAE                  1.907056      1.848605      1.819043       1.89292   \n",
       "MBE                    0.1047      -0.21955     -0.255901      0.041147   \n",
       "PBIAS                4.900371    -10.275775     -11.97717      1.925849   \n",
       "KGE                  0.561263      0.484885      0.453894      0.537788   \n",
       "spearman             0.643303      0.644665      0.642815      0.645777   \n",
       "std                  5.877529      5.074859      4.752594      5.571073   \n",
       "obs_std              8.213137      8.213137      8.213137      8.213137   \n",
       "r_heavy              0.330037      0.419826      0.428864       0.34063   \n",
       "NSE_heavy           -3.530115     -3.583058     -4.091741     -3.633166   \n",
       "RMSE_heavy         102.953092    103.552942    109.148546    104.117494   \n",
       "MAE_heavy           91.907491     93.438032     99.976461     93.694819   \n",
       "MBE_heavy          -91.619893    -93.328411    -99.976461    -93.122737   \n",
       "PBIAS_heavy        -64.250536    -65.448673    -70.110769    -65.304439   \n",
       "KGE_heavy           -0.028664      0.042843     -0.038276     -0.032375   \n",
       "spearman_heavy       0.296287      0.330496      0.330198      0.313718   \n",
       "std_obs_heavy       48.370969     48.370969     48.370969     48.370969   \n",
       "std_model_heavy     26.929646     29.562571     23.693768      26.49342   \n",
       "r_ext                0.406404      0.462194      0.457922      0.409176   \n",
       "NSE_ext             -1.740517      -1.94827      -2.19272     -1.857111   \n",
       "RMSE_ext            65.703766      68.14871     70.917672     67.086877   \n",
       "MAE_ext             55.008378     58.914789     61.789451     57.002697   \n",
       "MBE_ext            -54.362611    -58.030268    -61.496842    -56.047848   \n",
       "PBIAS_ext          -58.965309    -62.943494    -66.703571     -60.79323   \n",
       "KGE_ext              0.063112      0.088012        0.0046      0.055401   \n",
       "spearman_ext         0.342814      0.354753      0.345408      0.347643   \n",
       "std_obs_ext         39.689354     39.689354     39.689354     39.689354   \n",
       "std_model_ext       22.957886     24.508524     19.764065     23.152077   \n",
       "POD                  0.854681      0.856092      0.844313      0.864662   \n",
       "FAR                  0.450673       0.45056      0.440181      0.459744   \n",
       "BIAS                 1.555869      1.558116      1.508189      1.600466   \n",
       "CSI                  0.502402      0.502984      0.507437      0.498133   \n",
       "POD_heavy            0.028889      0.064444          0.02      0.033333   \n",
       "FAR_heavy            0.566667      0.508475      0.526316      0.634146   \n",
       "BIAS_heavy           0.066667      0.131111      0.042222      0.091111   \n",
       "CSI_heavy            0.027837      0.060417      0.019565      0.031513   \n",
       "POD_ex               0.156357      0.134593       0.08362       0.15063   \n",
       "FAR_ex               0.494444      0.473094      0.365217      0.484314   \n",
       "BIAS_ex              0.309278      0.255441       0.13173      0.292096   \n",
       "CSI_ex               0.135618      0.120082      0.079781      0.131962   \n",
       "KS                       -1.0          -1.0          -1.0          -1.0   \n",
       "P_value(t-test)          None          None          None          None   \n",
       "\n",
       "                  LSTM_RA_0      CAL_P        PDIR     ERA5_tp  \n",
       "r                  0.662532   0.568148    0.389067    0.596399  \n",
       "NSE                0.433499   0.003661   -0.384067   -0.067623  \n",
       "RMSE               6.181722   8.198091    9.662458    8.486294  \n",
       "MAE                1.819593   2.501195    2.750997    2.136513  \n",
       "MBE               -0.255838   0.478239     0.06976   -2.136476  \n",
       "PBIAS            -11.974236  22.383457    3.265023  -99.995429  \n",
       "KGE                0.459853   0.496499    0.376392   -0.470622  \n",
       "spearman           0.628409   0.491643    0.394756    0.628714  \n",
       "std                4.891781   9.281308     9.20492    0.000303  \n",
       "obs_std            8.213137   8.213137    8.213137    8.213137  \n",
       "r_heavy            0.357449   0.321074    0.245752    0.332921  \n",
       "NSE_heavy         -4.033886  -2.366826    -4.34352   -8.690413  \n",
       "RMSE_heavy       108.526665  88.755468  111.814595   150.57606  \n",
       "MAE_heavy         98.424427  73.962012     95.5456  142.595434  \n",
       "MBE_heavy        -98.305995  -62.77035  -80.686756 -142.595434  \n",
       "PBIAS_heavy      -68.939317 -44.019137  -56.583424  -99.998294  \n",
       "KGE_heavy         -0.051201   0.164652   -0.076347   -0.563613  \n",
       "spearman_heavy     0.306711    0.29487    0.284163     0.24192  \n",
       "std_obs_heavy     48.370969  48.370969   48.370969   48.370969  \n",
       "std_model_heavy   25.843945  58.412689   73.480314    0.001824  \n",
       "r_ext              0.431503   0.407156     0.31304    0.346135  \n",
       "NSE_ext           -2.174039  -1.406075   -2.739546    -5.39561  \n",
       "RMSE_ext          70.709895  61.564252   76.750896  100.372563  \n",
       "MAE_ext           61.141576  49.884181   64.604926   92.192452  \n",
       "MBE_ext          -60.820807 -39.534171  -52.703391  -92.192452  \n",
       "PBIAS_ext        -65.970298 -42.881396  -57.165608  -99.998075  \n",
       "KGE_ext            0.015433   0.249174    0.040392    -0.55802  \n",
       "spearman_ext       0.339031   0.315823     0.25269    0.273117  \n",
       "std_obs_ext       39.689354  39.689354   39.689354   39.689354  \n",
       "std_model_ext     21.459206   46.37727   53.560365    0.001515  \n",
       "POD                0.840508   0.619979    0.720179         0.0  \n",
       "FAR                 0.43237   0.472814    0.629739   Undefined  \n",
       "BIAS               1.480732   1.176016    1.945056         0.0  \n",
       "CSI                0.512435   0.398435    0.323694         0.0  \n",
       "POD_heavy          0.031111   0.308889    0.213333         0.0  \n",
       "FAR_heavy          0.517241   0.747731    0.861272   Undefined  \n",
       "BIAS_heavy         0.064444   1.224444    1.537778         0.0  \n",
       "CSI_heavy          0.030108   0.161253    0.091778         0.0  \n",
       "POD_ex              0.10882   0.318442    0.212486         0.0  \n",
       "FAR_ex              0.41896   0.770058    0.804942   Undefined  \n",
       "BIAS_ex            0.187285    1.38488    1.089347         0.0  \n",
       "CSI_ex             0.100903   0.154102    0.113213         0.0  \n",
       "KS                     -1.0       -1.0        -1.0        -1.0  \n",
       "P_value(t-test)        None       None        None        None  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation \n",
    "import evaluation_tools\n",
    "\n",
    "ms = [ 'xx', 'LSTM_RA_3(-4)','LSTM_RA_3(-3)',  'LSTM_RA_3(-2)','LSTM_RA_3(-1)', 'LSTM_RA_3'  ,  'LSTM_RA_2'  , 'LSTM_RA_1'  ,\n",
    "      'LSTM_RA_0(-4)' , 'LSTM_RA_0(-3)'  , 'LSTM_RA_0(-2)' , \n",
    "      'LSTM_RA_0(-1)' , 'LSTM_RA_0' , 'CAL_P'   ,'PDIR' , 'ERA5_tp']\n",
    "\n",
    "t = 'test'\n",
    "\n",
    "out = []\n",
    "for m in ms :\n",
    "    ev = evaluation_tools.evaluation_criteria(  np.array(df[t][obs_key])  , np.array( df[t][m])  , th =1 , threshold_heavy= 100 ) \n",
    "    out.append(ev) \n",
    "out = pd.DataFrame(out , index = ms)\n",
    "out.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_key = 'PRCP'\n",
    "ord_Keys =[  'HQ_P(-1)-(13, 13)', 'HQ_P(-2)-(13, 13)', 'HQ_P(-3)-(13, 13)', 'HQ_P(-4)-(13, 13)']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'Australian Capital Territory', b'New South Wales',\n",
       "       b'Northern Territory', b'Queensland', b'South Australia',\n",
       "       b'Tasmania', b'Victoria', b'Western Australia'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(DF['state_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ind = np.where(DF['state_name'] == 'Victoria' )[0] \n",
    "for k in list(DF.keys()):\n",
    "    DF[k]  = DF[k][state_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.array(DF['LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.0166666 141.2666666\n"
     ]
    }
   ],
   "source": [
    "print(max(lon)  , min(lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_indx= np.where(DF['LONGITUDE'] > 142 )[0] \n",
    "for k in list(DF.keys()):\n",
    "    DF[k]  = DF[k][lon_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_ind= np.where(DF['LATITUDE'] < -35 )[0] \n",
    "for k in list(DF.keys()):\n",
    "    DF[k]  = DF[k][lat_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_year = 2020\n",
    "\n",
    "train_indx = np.where(DF['YEAR'] <= split_year )\n",
    "test_indx = np.where(DF['YEAR'] > split_year )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Input_2D(DF, indx, Keys  , Rescale = False):\n",
    "    X_train = []\n",
    "    df = {}\n",
    "    if Rescale == True :\n",
    "        for k in Keys:\n",
    "            mean = np.mean(DF[k])\n",
    "            std = np.std(DF[k])\n",
    "            df[k] = (DF[k] - mean / std)\n",
    "    else :\n",
    "        df  = DF\n",
    "    for i in indx[0] :\n",
    "        x =[ ] \n",
    "        for k in Keys:\n",
    "            x.append(df[k][i])\n",
    "        x = np.array(x)\n",
    "        X_train.append( np.reshape(x ,  newshape= (13 , 13 , 4) ))\n",
    "    return np.array(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Re = False\n",
    "x_train = Input_2D(DF, train_indx  , ord_Keys , Rescale=Re)\n",
    "x_test = Input_2D(DF, test_indx , ord_Keys, Rescale=Re)\n",
    "\n",
    "obs_train = DF[obs_key][train_indx]\n",
    "obs_test = DF[obs_key][test_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159264, 13, 13, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S4055367\\AppData\\Local\\anaconda3\\envs\\ML\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m4,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m3,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,769</span> (128.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,769\u001b[0m (128.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,769</span> (128.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,769\u001b[0m (128.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu', input_shape=( 13, 13 ,4)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=( 7, 7 ,4)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=( 3, 3 ,4)))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnar(x): return np.array([x]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.2015 - loss: 47.7751\n",
      "Epoch 2/7\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 53ms/step - accuracy: 0.3249 - loss: 46.6485\n",
      "Epoch 3/7\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 57ms/step - accuracy: 0.3294 - loss: 46.3471\n",
      "Epoch 4/7\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - accuracy: 0.3203 - loss: 45.5130\n",
      "Epoch 5/7\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 55ms/step - accuracy: 0.3268 - loss: 45.3759\n",
      "Epoch 6/7\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 61ms/step - accuracy: 0.3320 - loss: 44.8198\n",
      "Epoch 7/7\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 66ms/step - accuracy: 0.3307 - loss: 45.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2705b9efd10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( x_train  , columnar(obs_train), batch_size= 1000 ,epochs=7, verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31683/31683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.39611414],\n",
       "       [0.39611414, 1.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict = model.predict(x_train)\n",
    "np.corrcoef(  train_predict.T[0] , obs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15569/15569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.37289315],\n",
       "       [0.37289315, 1.        ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pr = model.predict(x_test)\n",
    "np.corrcoef(  test_pr.T[0]  , obs_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "evdf = pd.DataFrame( {'pr'  : test_pr.T[0] * 6  , 'obs'  : obs_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='pr', ylabel='obs'>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evdf.plot.scatter(x='pr' ,\n",
    "                y='obs' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation_tools as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.evaluation_criteria( obs_test  ,  test_pr.T[0] *5   , th=1,\n",
    "    threshold_heavy=25,\n",
    "    threshold_ex=60,\n",
    "    interval=[ i  for i in [ 0 , 5 , 10 , 25 , 60  , 100]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANT colony \n",
    "x_train_ant = train_predict\n",
    "obs_train_ant = columnar(obs_train)\n",
    "obs_test_ant = columnar(obs_test)\n",
    "ep = 1E-10\n",
    "\n",
    "def sgn(x , th):\n",
    "    return ((x - th + ep ) / np.absolute(x - th  +ep)  + 1)/2 \n",
    "\n",
    "def CSI(  O , M ,th ):\n",
    "    fo = sgn(O , th)\n",
    "    fm = sgn(M ,th)\n",
    "    return np.sum(fo * fm )  /  (np.sum(fo +fm) - np.sum(fo*fm))\n",
    "\n",
    "mlp_model = MLP(nn_shape= [8 ,4, 1 ] , inp_feat=  x_train_ant.shape[1])\n",
    "\n",
    "def fitness_function( solution  ):\n",
    "    # solution =  solution/sqrt(number_of_parameters)\n",
    "    mlp_model.update( solution)\n",
    "    y  =  mlp_model.feed_forward(x_train_ant)\n",
    "    return np.mean((y-obs_train_ant)**2)**0.5 /8  -  CSI(obs_train_ant , y  , 1 )   -  CSI(obs_train_ant , y  , 25 )   -  CSI(obs_train_ant , y  , 60 )\n",
    "import numpy\n",
    "n_var = mlp_model.Sum_params\n",
    "\n",
    "problem_dict = {\n",
    "    \"bounds\": FloatVar(  lb=(-1.,) * n_var, ub=(1.,) * n_var, name=\"delta\"),\n",
    "    \"obj_func\": fitness_function,\n",
    "    \"minmax\": \"min\",}\n",
    "\n",
    "model_ant = ACOR.OriginalACOR(epoch=20, pop_size=20, sample_count = 25, intent_factor = 0.5, zeta = 1.0)\n",
    "\n",
    "g_best = model_ant.solve(problem_dict)\n",
    "x_test_ant =  test_pr\n",
    "mlp_model.update( g_best.solution)\n",
    "y_ant = mlp_model.feed_forward(x_test_ant)[:, 0]\n",
    "ev.evaluation_criteria(obs_test  , test_pr.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def conv2d(input, kernel, stride=1, padding=0):\n",
    "    batch_size, H, W, C = input.shape\n",
    "    K, kH, kW, _ = kernel.shape\n",
    "    out_H = (H - kH + 2 * padding) // stride + 1\n",
    "    out_W = (W - kW + 2 * padding) // stride + 1\n",
    "    output = np.zeros((batch_size, out_H, out_W, K))\n",
    "    input_padded = np.pad(input, ((0, 0), (padding, padding), (padding, padding), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        for k in range(K):\n",
    "            for h in range(out_H):\n",
    "                for w in range(out_W):\n",
    "                    h_start = h * stride\n",
    "                    w_start = w * stride\n",
    "                    h_end = h_start + kH\n",
    "                    w_end = w_start + kW\n",
    "                    output[b, h, w, k] = np.sum(input_padded[b, h_start:h_end, w_start:w_end, :] * kernel[k, :, :, :])\n",
    "    return output\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def squared_error_loss(output, target):\n",
    "    return 0.5 * np.sum((output - target) ** 2)\n",
    "\n",
    "def squared_error_loss_derivative(output, target):\n",
    "    return output - target\n",
    "\n",
    "def conv2d_backward(input, kernel, output_grad, stride=1, padding=0):\n",
    "    batch_size, H, W, C = input.shape\n",
    "    K, kH, kW, _ = kernel.shape\n",
    "    out_H, out_W = output_grad.shape[1:3]\n",
    "    input_grad = np.zeros_like(input)\n",
    "    kernel_grad = np.zeros_like(kernel)\n",
    "    input_padded = np.pad(input, ((0, 0), (padding, padding), (padding, padding), (0, 0)), mode='constant', constant_values=0)\n",
    "    input_grad_padded = np.pad(input_grad, ((0, 0), (padding, padding), (padding, padding), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        for k in range(K):\n",
    "            for h in range(out_H):\n",
    "                for w in range(out_W):\n",
    "                    h_start = h * stride\n",
    "                    w_start = w * stride\n",
    "                    h_end = h_start + kH\n",
    "                    w_end = w_start + kW\n",
    "                    input_grad_padded[b, h_start:h_end, w_start:w_end, :] += output_grad[b, h, w, k] * kernel[k, :, :, :]\n",
    "                    kernel_grad[k, :, :, :] += output_grad[b, h, w, k] * input_padded[b, h_start:h_end, w_start:w_end, :]\n",
    "    \n",
    "    if padding > 0:\n",
    "        input_grad = input_grad_padded[:, padding:-padding, padding:-padding, :]\n",
    "    else:\n",
    "        input_grad = input_grad_padded\n",
    "    \n",
    "    return input_grad, kernel_grad\n",
    "\n",
    "def flatten(input):\n",
    "    batch_size = input.shape[0]\n",
    "    return input.reshape(batch_size, -1)\n",
    "\n",
    "def dense(input, weights, biases):\n",
    "    return np.dot(input, weights) + biases\n",
    "\n",
    "def dense_backward(input, weights, output_grad):\n",
    "    input_grad = np.dot(output_grad, weights.T)\n",
    "    weights_grad = np.dot(input.T, output_grad)\n",
    "    biases_grad = np.sum(output_grad, axis=0)\n",
    "    return input_grad, weights_grad, biases_grad\n",
    "\n",
    "def train(X, y, kernel, dense_weights, dense_biases, batch_sample ,  learning_rate=0.01, epochs=10, stride=1, padding=1):\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "            \n",
    "        b_size = batch_sample\n",
    "\n",
    "        splits = np.arange(0 , n_samples  +b_size,   b_size )\n",
    "        splits[-1] = len(X)\n",
    "        learning_rate = learning_rate / (epoch+1)\n",
    "        for i in tqdm(range( len(splits)-1), desc=f\"epoch {epoch+1} : \" , ncols= 100  ,colour='blue'):#  range(len(splits)-1):\n",
    "            input_volume =  X[splits[i]:splits[i+1] ]\n",
    "            target = np.array([y]).T[splits[i]:splits[i+1] ]  \n",
    "            conv_output = conv2d(input_volume, kernel, stride=stride, padding=padding)\n",
    "            activated_output = relu(conv_output)\n",
    "            flattened_output = flatten(activated_output)\n",
    "            dense_output = dense(flattened_output, dense_weights, dense_biases)\n",
    "            loss = squared_error_loss(dense_output, target)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss_grad = squared_error_loss_derivative(dense_output, target)\n",
    "            dense_input_grad, dense_weights_grad, dense_biases_grad = dense_backward(flattened_output, dense_weights, loss_grad)\n",
    "            relu_grad = relu_derivative(activated_output) * dense_input_grad.reshape(activated_output.shape)\n",
    "            input_grad, kernel_grad = conv2d_backward(input_volume, kernel, relu_grad, stride=stride, padding=padding)\n",
    "            \n",
    "            # Update weights with gradient clipping\n",
    "            max_grad_norm = 1.0\n",
    "            kernel_grad = np.clip(kernel_grad, -max_grad_norm, max_grad_norm)\n",
    "            dense_weights_grad = np.clip(dense_weights_grad, -max_grad_norm, max_grad_norm)\n",
    "            dense_biases_grad = np.clip(dense_biases_grad, -max_grad_norm, max_grad_norm)\n",
    "            \n",
    "            kernel -= learning_rate * kernel_grad\n",
    "            dense_weights -= learning_rate * dense_weights_grad\n",
    "            dense_biases -= learning_rate * dense_biases_grad\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss}, RMSE: {(loss/target.shape[0])**0.5}\" )\n",
    "    return  kernel, dense_weights, dense_biases\n",
    "\n",
    "# Example usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_samples = x_train.shape[0]\n",
    "    h = 7\n",
    "    w = 7\n",
    "    s = 4\n",
    "    l = 16\n",
    "    output_size = 1  # Assuming a single output per sample\n",
    "    #  np.random.rand(n_samples, h, w, s)  # Batch of 5 samples, each of shape (h, w, s)\n",
    "    kernel_o = np.random.randn( l, 3, 3, s  ) ##np.random.randn(l, 3, 3, s)  # 2 output channels, kernel size 3x3, s input channels\n",
    "     # np.random.rand(n_samples, output_size)  # Batch of 5 target samples, each of shape (output_size)\n",
    "    dense_weights_o = np.random.rand(h * w * l, output_size)  # Fully connected layer weights\n",
    "    dense_biases_o = np.random.rand(output_size)  # Fully connected layer biases\n",
    "    learning_rate = 1\n",
    "    epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "    kernel_o, dense_weights_o , dense_biases_o = train( X = np.round(x_train[0:n_samples],2), \n",
    "                                                        y = np.round(obs_train[0:n_samples],2) , \n",
    "                                                        kernel= kernel_o,\n",
    "                                                        dense_weights= dense_weights_o , \n",
    "                                                        dense_biases = dense_biases_o, \n",
    "                                                        batch_sample= 1000 , \n",
    "                                                        learning_rate=learning_rate , \n",
    "                                                        epochs=epochs, \n",
    "                                                        stride=1, padding=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  1000,  2000,  3000,  4000,  5000,  6000,  7000,  8000,\n",
       "        9000, 10000])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0 , n_samples+1000 ,   1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.13122337],\n",
       "       [0.13122337, 1.        ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_volume =np.round(  x_train[0:n_samples ] ,2 ) \n",
    "target = np.round( np.array([obs_train]).T[0:n_samples]   , 2 )\n",
    "\n",
    "conv_output = conv2d(input_volume, kernel_o, stride=1, padding=1)\n",
    "activated_output = relu(conv_output)\n",
    "flattened_output = flatten(activated_output)\n",
    "dense_output = dense(flattened_output, dense_weights_o, dense_biases_o)\n",
    "\n",
    "np.corrcoef(  dense_output.T[0]  , obs_train[0:n_samples ]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_volume =np.round(  x_test[0:n_samples ] ,2 ) \n",
    "target = np.round( np.array([obs_test]).T[0:n_samples]   , 2 )\n",
    "\n",
    "conv_output = conv2d(input_volume, kernel_o, stride=1, padding=1)\n",
    "activated_output = relu(conv_output)\n",
    "flattened_output = flatten(activated_output)\n",
    "dense_output = dense(flattened_output, dense_weights_o, dense_biases_o)\n",
    "\n",
    "np.corrcoef(  dense_output.T[0]  , obs_train[0:n_samples ]  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimise your code for handling 1 million samples, we need to make several improvements, primarily focusing on leveraging vectorised operations provided by NumPy and avoiding nested loops wherever possible. Below are the optimised functions and the main training loop.\n",
    "\n",
    "Optimised Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def conv2d(input, kernel, stride=1, padding=0):\n",
    "    batch_size, H, W, C = input.shape\n",
    "    K, kH, kW, _ = kernel.shape\n",
    "    out_H = (H - kH + 2 * padding) // stride + 1\n",
    "    out_W = (W - kW + 2 * padding) // stride + 1\n",
    "    output = np.zeros((batch_size, out_H, out_W, K))\n",
    "    input_padded = np.pad(input, ((0, 0), (padding, padding), (padding, padding), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    for k in range(K):\n",
    "        for h in range(out_H):\n",
    "            for w in range(out_W):\n",
    "                h_start = h * stride\n",
    "                w_start = w * stride\n",
    "                h_end = h_start + kH\n",
    "                w_end = w_start + kW\n",
    "                output[:, h, w, k] = np.sum(input_padded[:, h_start:h_end, w_start:w_end, :] * kernel[k, :, :, :], axis=(1, 2, 3))\n",
    "    return output\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def squared_error_loss(output, target):\n",
    "    return 0.5 * np.sum((output - target) ** 2)\n",
    "\n",
    "def squared_error_loss_derivative(output, target):\n",
    "    return output - target\n",
    "\n",
    "def conv2d_backward(input, kernel, output_grad, stride=1, padding=0):\n",
    "    batch_size, H, W, C = input.shape\n",
    "    K, kH, kW, _ = kernel.shape\n",
    "    out_H, out_W = output_grad.shape[1:3]\n",
    "    input_grad = np.zeros_like(input)\n",
    "    kernel_grad = np.zeros_like(kernel)\n",
    "    input_padded = np.pad(input, ((0, 0), (padding, padding), (padding, padding), (0, 0)), mode='constant', constant_values=0)\n",
    "    input_grad_padded = np.pad(input_grad, ((0, 0), (padding, padding), (padding, padding), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    for k in range(K):\n",
    "        for h in range(out_H):\n",
    "            for w in range(out_W):\n",
    "                h_start = h * stride\n",
    "                w_start = w * stride\n",
    "                h_end = h_start + kH\n",
    "                w_end = w_start + kW\n",
    "                input_grad_padded[:, h_start:h_end, w_start:w_end, :] += output_grad[:, h, w, k][:, np.newaxis, np.newaxis, np.newaxis] * kernel[k, :, :, :]\n",
    "                kernel_grad[k, :, :, :] += np.sum(output_grad[:, h, w, k][:, np.newaxis, np.newaxis, np.newaxis] * input_padded[:, h_start:h_end, w_start:w_end, :], axis=0)\n",
    "    \n",
    "    if padding > 0:\n",
    "        input_grad = input_grad_padded[:, padding:-padding, padding:-padding, :]\n",
    "    else:\n",
    "        input_grad = input_grad_padded\n",
    "    \n",
    "    return input_grad, kernel_grad\n",
    "\n",
    "def flatten(input):\n",
    "    batch_size = input.shape[0]\n",
    "    return input.reshape(batch_size, -1)\n",
    "\n",
    "def dense(input, weights, biases):\n",
    "    return np.dot(input, weights) + biases\n",
    "\n",
    "def dense_backward(input, weights, output_grad):\n",
    "    input_grad = np.dot(output_grad, weights.T)\n",
    "    weights_grad = np.dot(input.T, output_grad)\n",
    "    biases_grad = np.sum(output_grad, axis=0)\n",
    "    return input_grad, weights_grad, biases_grad\n",
    "\n",
    "def train(input_volume, target, kernel, dense_weights, dense_biases, learning_rate=0.01, epochs=10, stride=1, padding=1):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Forward pass\n",
    "        conv_output = conv2d(input_volume, kernel, stride=stride, padding=padding)\n",
    "        activated_output = relu(conv_output)\n",
    "        flattened_output = flatten(activated_output)\n",
    "        dense_output = dense(flattened_output, dense_weights, dense_biases)\n",
    "        loss = squared_error_loss(dense_output, target)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss_grad = squared_error_loss_derivative(dense_output, target)\n",
    "        dense_input_grad, dense_weights_grad, dense_biases_grad = dense_backward(flattened_output, dense_weights, loss_grad)\n",
    "        relu_grad = relu_derivative(activated_output) * dense_input_grad.reshape(activated_output.shape)\n",
    "        input_grad, kernel_grad = conv2d_backward(input_volume, kernel, relu_grad, stride=stride, padding=padding)\n",
    "        \n",
    "        # Update weights with gradient clipping\n",
    "        max_grad_norm = 1.0\n",
    "        kernel_grad = np.clip(kernel_grad, -max_grad_norm, max_grad_norm)\n",
    "        dense_weights_grad = np.clip(dense_weights_grad, -max_grad_norm, max_grad_norm)\n",
    "        dense_biases_grad = np.clip(dense_biases_grad, -max_grad_norm, max_grad_norm)\n",
    "        \n",
    "        kernel -= learning_rate * kernel_grad\n",
    "        dense_weights -= learning_rate * dense_weights_grad\n",
    "        dense_biases -= learning_rate * dense_biases_grad\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss}, RMSE: {(loss/target.shape[0])**0.5}\" )\n",
    "    return kernel, dense_weights, dense_biases\n",
    "\n",
    "# Example usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_samples = int(0.5E6)\n",
    "    h = 7\n",
    "    w = 7\n",
    "    s = 4\n",
    "    l = 16\n",
    "    output_size = 1  # Assuming a single output per sample\n",
    "    input_volume =  x_train[0:n_samples ]  #  np.random.rand(n_samples, h, w, s)  # Batch of 5 samples, each of shape (h, w, s)\n",
    "    kernel = np.random.randn( l, 3, 3, s  ) ##np.random.randn(l, 3, 3, s)  # 2 output channels, kernel size 3x3, s input channels\n",
    "    target =  np.array([obs_train]).T[0:n_samples ]  # np.random.rand(n_samples, output_size)  # Batch of 5 target samples, each of shape (output_size)\n",
    "    dense_weights = np.random.rand(h * w * l, output_size)  # Fully connected layer weights\n",
    "    dense_biases = np.random.rand(output_size)  # Fully connected layer biases\n",
    "    learning_rate = 1\n",
    "    epochs = 10\n",
    "    kernel_o, dense_weights_o , dense_biases_o = train(input_volume, target, kernel, dense_weights, dense_biases, learning_rate=learning_rate , epochs=epochs, stride=1, padding=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train[0]\n",
    "x_test = X_test[0] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(6, 16)\n",
      "  (conv2): GCNConv(16, 1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['PYTHONWARNINGS'] = \"ignore\"\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv( x_train.shape[1], hidden_channels)\n",
    "        self.conv2 = GCNConv( 16 ,1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index =  np.zeros(   (2,  x_train.shape[0])  )+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_train = []\n",
    "for i in range( x_train.shape[0] ) :\n",
    "    edge_index_train.append( [ i , i+1]  )\n",
    "edge_index_train = np.array(edge_index_train).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_test = []\n",
    "for i in range( x_train.shape[0] ) :\n",
    "    edge_index_test.append( [ i , i]  )\n",
    "edge_index_test = np.array(edge_index_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Define the Graph Neural Network model\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.fc1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.fc2 = GCNConv(hidden_dim, output_dim)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.fc1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Assuming you have your data loaded into X_train and y_train\n",
    "n1 = int(x_train.shape[0]/2)\n",
    "n2 = int(x_test.shape[0]/2)\n",
    "\n",
    "x_train_tensor =  torch.from_numpy(x_train ).type(torch.FloatTensor)[ 0:n1  , :]\n",
    "x_test_tensor =  torch.from_numpy(x_test).type(torch.FloatTensor)[ 0:n2  , :]\n",
    "y_train = torch.from_numpy(obs_train).type(torch.FloatTensor)[ 0:n1  ]\n",
    "y_test = torch.from_numpy(obs_test).type(torch.FloatTensor)[ 0:n2  ]\n",
    "\n",
    "\n",
    "edge_index_train_tensor = torch.from_numpy(edge_index_train.astype(int) ).type(torch.IntTensor)[ :  , 0:n1  ]\n",
    "edge_index_test_tensor = torch.from_numpy(edge_index_test.astype(int) ).type(torch.IntTensor)[ :  , 0:n2 ]\n",
    "edge_index_train_tensor[-1,-1] = 0\n",
    "edge_index_test_tensor[-1,-1]  = 0\n",
    "\n",
    "# Initialize the GNN model\n",
    "model = GNN( input_dim=x_train.shape[1],  hidden_dim=8, output_dim=1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model.forward(x_train_tensor , edge_index_train_tensor )\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    2,  ..., 9997, 9998, 9999],\n",
       "        [   1,    2,    3,  ..., 9998, 9999,    0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Once trained, you can use the model to make predictions\n",
    "predictions = model.forward(x_test_tensor, edge_index_test_tensor)\n",
    "pr = [ ]\n",
    "for p in predictions:\n",
    "    pr.append( float(p))\n",
    "pr = np.array(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_tools.evaluation_criteria( y_test.numpy() ,   pr )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import evaluation_tools\n",
    "\n",
    "ms = ['CNN_RA_(7,7)', 'CNN_RA_C_(7,7)' , 'CNN_RA_C_[-1](7,7)', 'CNN_RA_C_[-2](7,7)', 'CNN_RA_C_[-3](7,7)' , 'CNN_RA_(5,5)', 'CNN_RA_C_(5,5)' , 'CNN_RA_(3,3)', 'CNN_RA_C_(3,3)'   ,  'LSTM_RA_3(-4)', 'CAL_P'   ,'PDIR' , 'ERA5_tp']\n",
    "\n",
    "t = 'test'\n",
    "ev_df = pd.DataFrame()\n",
    "\n",
    "for k in ms :\n",
    "    for hdf in hdfs :\n",
    "        if k in list(hdf.keys()):\n",
    "            DF[k] = np.array(hdf[k])\n",
    "\n",
    "test = DF[DF['YEAR'] > 2020]\n",
    "for k in list(test.keys()):\n",
    "    df['test'][k]   = np.array(test[k])\n",
    "\n",
    "df['test']['ERA5_tp']  = df['test']['ERA5_tp'] *24*1000\n",
    "\n",
    "out = []\n",
    "for m in ms :\n",
    "    ev = evaluation_tools.evaluation_criteria(  np.array(df[t][obs_key])  , np.array( df[t][m])  , th =1  ) \n",
    "    out.append(ev) \n",
    "\n",
    "out = pd.DataFrame(out , index = ms)\n",
    "out.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save outputs\n",
    "import xarray\n",
    "try: del df['train']['dim_0'] \n",
    "except: pass \n",
    "\n",
    "try: del df['test']['dim_0'] \n",
    "except: pass \n",
    "\n",
    "of_train =  r\"..\\dataset\\train_02.nc4\"\n",
    "of_test = r\"..\\dataset\\test_02.nc4\"\n",
    "\n",
    "xr = xarray.Dataset(  df['train']  ) \n",
    "xr.to_netcdf( of_train , format=\"NETCDF4\")\n",
    "\n",
    "xr = xarray.Dataset(  df['test']  ) \n",
    "xr.to_netcdf( of_test , format=\"NETCDF4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parent Data Frame\n",
    "for K in ord_Keys :\n",
    "    for k in K:\n",
    "        try: del DF[k]  \n",
    "        except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict_to_hdf( DF  ,   r\"D:\\Projects\\precipitation_AUS\\dataset\\0025_WA/DF1.hdf5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.concat([df['train']  , df['test']])\n",
    "DF['Date']  = DF['YEAR'].astype(str) + '-' +DF['MONTH'].astype(str) +'-' + DF['DAY'].astype(str)\n",
    "xr = xarray.Dataset(  DF ) \n",
    "\n",
    "xr.to_netcdf( r\"..\\dataset\\dataset_2014-2024_0024.nc4\" , format=\"NETCDF4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reza",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
